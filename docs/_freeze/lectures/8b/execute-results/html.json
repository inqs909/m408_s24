{
  "hash": "30dcf43bf95574b4c56953e63bdc32c8",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Generalized Linear Models\"\nformat:\n  revealjs:\n    scrollable: true\n    navigation-mode: vertical\n    controls-layout: bottom-right\n    controls-tutorial: true\n    sc-sb-title: true\n    incremental: false \n    chalkboard:\n      src: chalkboard.json\n      storage: chalkboard_pres\n      theme: whiteboard\n      chalk-width: 4\nknitr:\n  opts_chunk: \n    echo: true\n    eval: false\n    message: false\n    warnings: false\n    comment: \"#>\" \n\nrevealjs-plugins:\n  - pointer\n  - verticator\n  \nfilters: \n  - reveal-header\n  - code-fullscreen\n\neditor: visual\n---\n\n\n## Learning Outcomes\n\n-   Exponential Family of Distributions\n\n-   Generalized Linear Models\n\n-   R Code\n\n# Exponential Family of Distributions\n\n## Exponential Family of Distributions\n\nAn exponential family of distributions are random variables that allow their probability density function to have the following form:\n\n$$\nf(y; \\theta,\\phi) = a(y,\\phi)\\exp\\left\\{\\frac{y\\theta-\\kappa(\\theta)}{\\phi}\\right\\}\n$$\n\n-   $\\theta$: is the canonical parameter (also a function of other parameters)\n\n-   $\\kappa(\\theta)$: is a known cumulant function\n\n-   $\\phi>0$: dispersion parameter function\n\n-   $a(y,\\phi)$: normalizing constant\n\n## Canonical Parameter\n\nThe canonical parameter represents the relationship between the random variable and the $E(Y)=\\mu$\n\n## Normal Distribution\n\n$$\nf(x;\\mu,\\sigma^2)=\\frac{1}{\\sqrt{2\\pi\\sigma^2}}e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}\n$$\n\n## Binomial Distribution\n\n$$\nf(x;n,p)=\\big(^n_x\\big) p^x(1-p)^{n-x}\n$$\n\n## Poisson Distribution\n\n$$\nf(x;\\lambda) = \\frac{e^{-\\lambda}\\lambda^x}{x!} \n$$\n\n## Common Distributions and Canonical Parameters\n\n| Random Variable   | Canonical Parameter                  |\n|-------------------|--------------------------------------|\n| Normal            | $\\mu$                                |\n| Binomial          | $\\log\\left(\\frac{\\mu}{1-\\mu}\\right)$ |\n| Negative Binomial | $\\log\\left(\\frac{\\mu}{\\mu+k}\\right)$ |\n| Poisson           | $\\log(\\mu)$                          |\n| Gamma             | $-\\frac{1}{\\mu}$                     |\n| Inverse Gaussian  | $-\\frac{1}{2\\mu^2}$                  |\n\n# Generalized Linear Models\n\n## Generalized Linear Models\n\nA generalized linear model (GLM) is used to model the association between an outcome variable (of any data type) and a set of predictor values. We estimate a set of regression coefficients $\\boldsymbol \\beta$ to explain how each predictor is related to the expected value of the outcome.\n\n## Generalized Linear Models\n\nA GLM is composed of a systematic and random component.\n\n## Random Component\n\nThe random component is the random variable that defines the randomness and variation of the outcome variable.\n\n## Systematic Component\n\nThe systematic component is the linear model that models the association between a set of predictors and the expected value of Y:\n\n$$\ng(\\mu)=\\eta=\\boldsymbol X_i^\\mathrm T \\boldsymbol \\beta\n$$\n\n-   $\\boldsymbol\\beta$: regression coefficients\n\n-   $\\boldsymbol X_i=(1, X_{i1}, \\ldots, X_{ip})^\\mathrm T$: design vector\n\n-   $\\eta$: linear model\n\n-   $\\mu=E(Y)$\n\n-   $g(\\cdot)$: link function\n\n# R Code\n\n## General R Code\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglm(formula, # <1>\n    data, # <2>\n    family) # <3>\n```\n:::\n\n\n1.  Supply a formula for R\n2.  Supply the data frame\n3.  Which family and link function is used to model data\n\n## Logistic (Binomial) Regression\n\nLogistic Regression is used when your outcome is binary:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglm(y~x, data, family = binomial())\n```\n:::\n\n\n## Poisson Regression\n\nPoisson Regression is used when the outcome is count data:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglm(y~x, data, family = poisson())\n```\n:::\n\n\n## Gamma Regression\n\nGamma Regression is used when modeling the association between predictors and positive continuous values:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglm(y~x, data, family = Gamma())\n```\n:::\n\n\n## Negative Binomial Regression\n\nNegative Binomial Regression is used four with overdispersed count data, where the variance is larger than expected.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(MASS)\nglm.nb(y~x, data)\n```\n:::\n\n\n## Inverse Gaussian Regression\n\nInverse Gaussian Regression is used for overly dispersed positive continuous data where Gamma Regression is inappropriate:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglm(y~x, data, family=inverse.gaussian())\n```\n:::\n\n\n# Examples\n\n## Fitting Models\n\nUse the `survival`, `MASS` and `GLMsData` R packages to fit the models for examples.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(GLMsData)\nlibrary(survival)\nlibrary(MASS)\nlibrary(magrittr)\n```\n:::\n\n\n## Logistic Regression\n\nWe are going to fit `y`, the presence of bacteria, and the predictors `ap`, active or placebo drug, and `hilo`, high/low compliance, from the `bacteria` data set.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbacteria %$% glm(y ~ ap + hilo, \n                 family = binomial(link = \"logit\")) %>% \n  summary\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> \n#> Call:\n#> glm(formula = y ~ ap + hilo, family = binomial(link = \"logit\"))\n#> \n#> Coefficients:\n#>             Estimate Std. Error z value Pr(>|z|)    \n#> (Intercept)   1.3539     0.2855   4.743 2.11e-06 ***\n#> app           0.7933     0.3748   2.116   0.0343 *  \n#> hilolo       -0.4816     0.3480  -1.384   0.1664    \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> (Dispersion parameter for binomial family taken to be 1)\n#> \n#>     Null deviance: 217.38  on 219  degrees of freedom\n#> Residual deviance: 209.87  on 217  degrees of freedom\n#> AIC: 215.87\n#> \n#> Number of Fisher Scoring iterations: 4\n```\n\n\n:::\n:::\n\n\n## Poisson Regression\n\nFit a model between the outcome `recur`, number of reccurrence, and predictors `treatment`, drugs or placebo, and `number`, the initial number of tumors, from the `bladder1` data set.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbladder1 %$% glm(recur ~ treatment + number, \n                 family = poisson(link = \"log\")) %>% \n  summary\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> \n#> Call:\n#> glm(formula = recur ~ treatment + number, family = poisson(link = \"log\"))\n#> \n#> Coefficients:\n#>                     Estimate Std. Error z value Pr(>|z|)    \n#> (Intercept)          1.00918    0.06057  16.661  < 2e-16 ***\n#> treatmentpyridoxine  0.25506    0.06889   3.702 0.000214 ***\n#> treatmentthiotepa   -0.45167    0.08626  -5.236 1.64e-07 ***\n#> number               0.11603    0.01620   7.164 7.82e-13 ***\n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> (Dispersion parameter for poisson family taken to be 1)\n#> \n#>     Null deviance: 868.47  on 293  degrees of freedom\n#> Residual deviance: 772.19  on 290  degrees of freedom\n#> AIC: 1529.5\n#> \n#> Number of Fisher Scoring iterations: 5\n```\n\n\n:::\n:::\n\n\n## Negative Binomial Regression\n\nFit a model between the outcome `Count`, viral activity (pock counts), and predictor `Dilution` factor from the `pock` data set.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(\"pock\")\npock %$% glm.nb(Count ~ Dilution) %>% summary\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> \n#> Call:\n#> glm.nb(formula = Count ~ Dilution, init.theta = 6.045172803, \n#>     link = log)\n#> \n#> Coefficients:\n#>             Estimate Std. Error z value Pr(>|z|)    \n#> (Intercept)  5.05810    0.09622   52.57   <2e-16 ***\n#> Dilution    -0.19204    0.01322  -14.53   <2e-16 ***\n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> (Dispersion parameter for Negative Binomial(6.0452) family taken to be 1)\n#> \n#>     Null deviance: 262.687  on 47  degrees of freedom\n#> Residual deviance:  48.891  on 46  degrees of freedom\n#> AIC: 427.26\n#> \n#> Number of Fisher Scoring iterations: 1\n#> \n#> \n#>               Theta:  6.05 \n#>           Std. Err.:  1.43 \n#> \n#>  2 x log-likelihood:  -421.261\n```\n\n\n:::\n:::\n\n\n## Gamma Regression\n\nFit a model between the outcome `Foliage`, foliage biomass, and predictor `DBH`, tree diameter at breast height, from the `lime` data set.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(\"lime\")\nlime %$% glm(Foliage ~ DBH, \n             family = Gamma(link = \"log\")) %>% \n  summary \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> \n#> Call:\n#> glm(formula = Foliage ~ DBH, family = Gamma(link = \"log\"))\n#> \n#> Coefficients:\n#>              Estimate Std. Error t value Pr(>|t|)    \n#> (Intercept) -1.786052   0.085994  -20.77   <2e-16 ***\n#> DBH          0.122388   0.004736   25.84   <2e-16 ***\n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> (Dispersion parameter for Gamma family taken to be 0.5432673)\n#> \n#>     Null deviance: 508.48  on 384  degrees of freedom\n#> Residual deviance: 189.57  on 383  degrees of freedom\n#> AIC: 831.65\n#> \n#> Number of Fisher Scoring iterations: 5\n```\n\n\n:::\n:::\n\n\n## Inverse Gaussian Regression\n\nFit a model between the outcome `Foliage`, foliage biomass, and predictor `DBH`, tree diameter at breast height, from the `lime` data set.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(\"lime\")\nlime %$% glm(Foliage ~ DBH, \n             family = inverse.gaussian(link = \"log\")) %>% \n  summary\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> \n#> Call:\n#> glm(formula = Foliage ~ DBH, family = inverse.gaussian(link = \"log\"))\n#> \n#> Coefficients:\n#>             Estimate Std. Error t value Pr(>|t|)    \n#> (Intercept)  -2.7290     0.1113  -24.53   <2e-16 ***\n#> DBH           0.2077     0.0118   17.59   <2e-16 ***\n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> (Dispersion parameter for inverse.gaussian family taken to be 1.571078)\n#> \n#>     Null deviance: 873.60  on 384  degrees of freedom\n#> Residual deviance: 542.83  on 383  degrees of freedom\n#> AIC: 1192.6\n#> \n#> Number of Fisher Scoring iterations: 16\n```\n\n\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}