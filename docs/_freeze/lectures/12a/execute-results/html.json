{
  "hash": "4b5e9718fca54b018d1c1139cb36e991",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Moving Beyond Linear Functions\"\nformat:\n  revealjs:\n    scrollable: true\n    navigation-mode: vertical\n    controls-layout: bottom-right\n    controls-tutorial: true\n    incremental: false \n    chalkboard:\n      src: chalkboard.json\n      storage: chalkboard_pres\n      theme: whiteboard\n      chalk-width: 4\nknitr:\n  opts_chunk: \n    echo: true\n    code-fold: true\n    eval: true\n    message: false\n    warnings: false\n    comment: \"#>\" \n    \nrevealjs-plugins:\n  - pointer\n  - verticator\n  \nfilters: \n  - reveal-header\n  - code-fullscreen\n  - reveal-auto-agenda\n\neditor: visual\n---\n\n\n# Motivating Example\n\n## Plot\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nlibrary(tidyverse)\nx <- rnorm(1000, sd = 0.25)\ny <- 1 + 5.3 * x - 45 * x^2 - 35.5 * x^3 + 60 * x^4 + rnorm(1000, sd = 0.5)\nggplot(tibble(x=x, y=y), aes(x,y)) + geom_point() + theme_bw()\n```\n\n::: {.cell-output-display}\n![](12a_files/figure-revealjs/unnamed-chunk-1-1.png){width=960}\n:::\n:::\n\n\n## Plot\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nlibrary(tidyverse)\nx <- rnorm(1000, sd = 3.5)\ny <- 1 + sinpi(x/8) + rnorm(1000, sd = 0.25)\nggplot(tibble(x=x, y=y), aes(x,y)) + geom_point() + theme_bw()\n```\n\n::: {.cell-output-display}\n![](12a_files/figure-revealjs/unnamed-chunk-2-1.png){width=960}\n:::\n:::\n\n\n# Polynomial Functions\n\n## Simple Linear Regression\n\nSimple Linear Regression models the association between one predictor `X` and an outcome `Y`:\n\n$$\nY = \\beta_0 + \\beta_1 X + \\varepsilon\n$$\n\n## Polynomial Regression\n\nPolynomial Regression models the association between predictor `X` and outcome `Y` with a polynomial function. For example, `X` can be related with `Y` with a cubic polynomial:\n\n$$\nY = \\beta_0 + \\beta_1 X + \\beta_2 X^2 + \\beta_3 X^3  + \\varepsilon\n$$\n\n## Finding estimates of $\\boldsymbol \\beta$\n\nThe estimates of $\\boldsymbol \\beta$ can be found by minimizing the following least squares formula for a given data set:\n\n$$\nL(\\boldsymbol \\beta) = \\sum^n_{i=1}(Y_i-\\hat Y_i)^2 \n$$\n\n$$\n\\hat Y_i = \\hat \\beta_0 + \\beta_1 X_i + \\beta_2 X_i^2 + \\beta_3 X_i^3\n$$\n\n## Polynomial Functions in GLMs\n\nPolynomial functions can be utilized in GLMs as well. The model below is for a logistic model:\n\n$$\nP(Y=1|X) = \\frac{\\exp\\left\\{ \\beta_0 + \\sum^3_{j=1}\\beta_j X^j \\right\\}}{1 +\\exp \\left\\{  \\beta_0 + \\sum^3_{j=1}\\beta_j X^j\\right\\}}\n$$\n\n## Fitting a Linear Model\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nx <- rnorm(1000, sd = 0.25)\ny <- 1 + 5.3 * x - 45 * x^2 - 35.5 * x^3 + 60 * x^4 + rnorm(1000, sd = 0.5)\nggplot(tibble(x=x, y=y), aes(x,y)) + \n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](12a_files/figure-revealjs/unnamed-chunk-3-1.png){width=960}\n:::\n:::\n\n\n## Fitting a Model\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nx <- rnorm(1000, sd = 0.25)\ny <- 1 + 5.3 * x - 45 * x^2 - 35.5 * x^3 + 60 * x^4 + rnorm(1000, sd = 0.5)\nggplot(tibble(x=x, y=y), aes(x,y)) + \n  geom_point() +\n  geom_smooth(method = \"lm\", formula = y ~ poly(x, 4)) +\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](12a_files/figure-revealjs/unnamed-chunk-4-1.png){width=960}\n:::\n:::\n\n\n## Polynomial Functions in R\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\nlm(y ~ poly(x, degree = p),\n   data)\n```\n:::\n\n\n## Individual terms in R\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\nlm(y ~ I(x^3),\n   data)\n```\n:::\n\n\n## Example\n\nSimulate the data below a fit a quadratic, cubic, and quartic model. Compute the mean squared error and $R^2$ for each model.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\nx <- rnorm(1000, sd = 0.25)\ny <- 1 + 5.3 * x - 45 * x^2 - 35.5 * x^3 + 60 * x^4 + rnorm(1000, sd = 0.5)\n```\n:::\n\n\n# Step Functions\n\n## Stepwise Function\n\nStepwise Function will add horizontal lines to best explain the data at different ranges of `X`.\n\n## Plot\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nlibrary(tidyverse)\nlibrary(splines)\nx <- rnorm(1000, sd = 0.25)\ny <- 1 + 5.3 * x - 45 * x^2 - 35.5 * x^3 + 60 * x^4 + rnorm(1000, sd = 0.5)\nggplot(tibble(x=x, y=y), aes(x,y)) + \n  geom_point() +\n  geom_smooth(method = \"lm\", formula = y ~ cut(x, 10)) +\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](12a_files/figure-revealjs/unnamed-chunk-8-1.png){width=960}\n:::\n:::\n\n\n## Constructing Model\n\n::: incremental\n-   Divide the range of `X` with `k` different intervals.\n-   Create `k-1` dummy variables indicating if the value `X` belongs to the interval or not.\n-   Construct a model incorporating all dummy variable and their corresponding coefficient.\n-   Find the estimates of the model by minimizing the Least Squares Estimator.\n:::\n\n## Step Functions in R\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\nlm(y ~ cut(x, 10),\n   data)\n```\n:::\n\n\n## Example\n\nSimulate the data below a fit step regression model with 10, 20, and 30 steps. Compute the mean squared error and $R^2$ for each model.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\nx <- rnorm(1000, sd = 0.25)\ny <- 1 + 5.3 * x - 45 * x^2 - 35.5 * x^3 + 60 * x^4 + rnorm(1000, sd = 0.5)\n```\n:::\n\n\n# Regression Splines\n\n## Basis Functions\n\nBasis functions model the outcome `Y` with a set of predefined functions on `X`:\n\n$$\nY = \\beta_0 + \\sum^p_{j=1}\\beta_jb_j(X) + \\varepsilon\n$$\n\n-   $\\boldsymbol \\beta$: Regression Coefficients\n-   $b_j(\\cdot)$: basis functions\n\n::: fragment\n$b_j(\\cdot)$ is allowed to be any function we define\n:::\n\n## Knots\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nx <- rnorm(1000, sd = 0.25)\ny <- 1 + 5.3 * x - 45 * x^2 + rnorm(1000, sd = 0.5)\nggplot(tibble(x=x, y=y), aes(x,y)) + \n  geom_point(size = 0.5) +\n  geom_smooth(method = \"lm\", formula = y ~ x + I(x * (x>0))) +\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](12a_files/figure-revealjs/unnamed-chunk-11-1.png){width=960}\n:::\n:::\n\n\n## More Knots\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nx <- rnorm(1000, sd = 0.25)\ny <- 1 + 5.3 * x - 45 * x^2 + rnorm(1000, sd = 0.5)\nggplot(tibble(x=x, y=y), aes(x,y)) + \n  geom_point(size = 0.5) +\n  geom_smooth(method = \"lm\", formula = y ~ bs(x, knots = c(-0.25, 0, 0.25), degree = 1)) +\n  geom_vline(xintercept = 0.25, lty = 2, lwd = .2, col = \"red\") +\n  geom_vline(xintercept = -0.25, lty = 2, lwd = .2, col = \"red\") +\n  geom_vline(xintercept = 0, lty = 2, lwd = .2, col = \"red\") +\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](12a_files/figure-revealjs/unnamed-chunk-12-1.png){width=960}\n:::\n:::\n\n\n## Truncated Power Basis Function\n\nOnce the number of knots and locations are chosen, a common basis function to utilize is the truncated power function:\n\n$$\nh(x,\\xi_l) = (x-\\xi_l)_+^p = \\left\\{\n\\begin{array}{cc}\n(x-\\xi_l)^p & x>\\xi_l\\\\\n0 & \\mathrm{Otherwise}\n\\end{array}\n\\right.\n$$\n\n## Spline Function\n\nFor $L$ knots:\n\n$$\nY = \\beta_0 + \\sum^p_{j=1}x^j\\beta_j + \\sum_{l=1}^Lh(x, \\xi_l)\\beta_{p+l} + \\varepsilon\n$$\n\n## Spline Functions Constraints\n\nWhen choosing basis functions, we want maintain the following constraints at the location of the knots:\n\n::: incremental\n-   Continuous\n-   First Differentiable\n-   Second Differentiable\n:::\n\n::: fragment\nA common choice is to use a cubic spline function\n:::\n\n## Cubic Splines\n\nFor $L$ knots:\n\n$$\nY = \\beta_0 + \\sum^3_{j=1}x^j\\beta_j + \\sum_{l=1}^Lh(x, \\xi_l)\\beta_{3+l} + \\varepsilon\n$$\n\n## Natural Cubic Splines\n\nNatural splines force the boundary knots to be fitted with simple lines instead of spline functions. The interior knots are fitted with spline functions.\n\n## Plot\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nx <- rnorm(1000, sd = 0.25)\ny <- 1 + 5.3 * x - 45 * x^2 - 35.5 * x^3 + 60 * x^4 + rnorm(1000, sd = 0.5)\nggplot(tibble(x=x, y=y), aes(x,y)) + \n  geom_point() +\n  geom_smooth(method = \"lm\", formula = y ~ bs(x, knots = c(-0.25, 0.25))) +\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](12a_files/figure-revealjs/unnamed-chunk-13-1.png){width=960}\n:::\n:::\n\n\n## Natural Cubic Splines\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nx <- rnorm(1000, sd = 0.25)\ny <- 1 + 5.3 * x - 45 * x^2 - 35.5 * x^3 + 60 * x^4 + rnorm(1000, sd = 0.5)\nggplot(tibble(x=x, y=y), aes(x,y)) + \n  geom_point() +\n  geom_smooth(method = \"lm\", formula = y ~ ns(x, knots = c(-0.25, 0.25))) +\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](12a_files/figure-revealjs/unnamed-chunk-14-1.png){width=960}\n:::\n:::\n\n\n## Cubic Splines in R\n\nThe `bs()` function in R from the `splines` package will construct the basis matrix to be fitted in the `lm` function. You will need to specify the locations of the knots. By default, the cubic splines are provided:\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\nlm(y ~ bs(x, knots = c()),\n   data)\n```\n:::\n\n\n## Natural Cubic Splines in R\n\nThe `ns()` function in R from the `splines` package will construct the basis matrix for natural cubic splines. You will need to specify the locations of the knots.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\nlm(y ~ ns(x, knots = c()),\n   data)\n```\n:::\n\n\n## Example\n\nSimulate the data below a fit regression model using cubic splines and natural cubic splines. Choose what you think is the appropriate number of knots and locations. Compute the mean squared error and $R^2$ for each model.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\nx <- rnorm(1000, sd = 0.25)\ny <- 1 + 5.3 * x - 45 * x^2 - 35.5 * x^3 + 60 * x^4 + rnorm(1000, sd = 0.5)\n```\n:::\n",
    "supporting": [
      "12a_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}