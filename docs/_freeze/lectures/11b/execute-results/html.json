{
  "hash": "71311be9dc9cfd97bd00873ae44ed5e1",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Resampling Methods\"\nformat:\n  revealjs:\n    scrollable: true\n    navigation-mode: vertical\n    controls-layout: bottom-right\n    controls-tutorial: true\n    incremental: false \n    chalkboard:\n      src: chalkboard.json\n      storage: chalkboard_pres\n      theme: whiteboard\n      chalk-width: 4\nknitr:\n  opts_chunk: \n    echo: true\n    eval: true\n    message: false\n    warnings: false\n    comment: \"#>\" \n    \nrevealjs-plugins:\n  - pointer\n  - verticator\n  \nfilters: \n  - reveal-header\n  - code-fullscreen\n\neditor: visual\n---\n\n\n## Learning Outcomes\n\n-   Cross-Validation\n\n    -   Leave-one-out\n\n    -   K-Fold\n\n-   Bootstrap Methods\n\n## Training Error Rate\n\nTraining Error Rate is the error rate of the data used to create the model of interest. It describes how well the model predicts the data used to construct it.\n\n## Test Error Rate\n\nTest Error Rate is the error rate of predicting a new data point using the current established model.\n\n## Test Error Rate\n\nIn order to obtain the test error rate, data not used to fit the model must be available\n\n::: fragment\nThis is not the case the majority of time.\n:::\n\n::: fragment\nNew methods have been developed to compute the test error rate using the existing data.\n:::\n\n# Cross-Validation\n\n## Cross-Validation\n\nA cross-validation approach is to obtain a good estimate of the error-rate of a machine learning algorithm. We split the data set into two categories: training and testing. The training data set is used to train the model, and the test data is used to test the model and compute the error rate.\n\n## Tuning Parameter\n\nA cross-validation approach is great when there is a tuning parameter. We can fit a model for different values of the tuning parameter, and we can choose which value results in the lowest error rate.\n\n## Training and Testing Data\n\nThe training and testing data sets are constructed by randomly assigning data points to one type of data.\n\n## LOOCV Cross-Validation\n\n-   Choose a set of tuning parameters to test.\n\n-   For each $k$th turning parameter, calculate the tuning parameter error for each value\n\n    -   Utilize the leave-one-out approach\n\n        -   For each observation fit a model with the remaining observations and fit the excluded value\n\n        -   Compute the following error:\n\n            $$\n            CVE_k = \\frac{1}{n}\\sum^n_{i=1}e_i \n            $$\n\n-   Identify the $k$th tuning parameter with the lowest $CVE_k$\n\n## K-Fold Cross-Validation\n\n-   Choose a set of tuning parameters to test.\n\n-   Create different K subsets of the data.\n\n-   For each $j$th turning parameter Calculate the tuning parameter error for each value\n\n    -   For each K subset, fit a model using the data excluding the Kth subset\n\n    -   Predict the values in the Kth subset using the fitted model\n\n    -   Repeat the process for each K subset\n\n    -   Compute the following error:\n\n        $$\n        CVE_j = \\frac{1}{n}\\sum^n_{i=1}e_i \n        $$\n\n-   Identify the $j$th tuning parameter with the lowest $CVE_j$\n\n## Executing in R\n\nSeveral R Packages have developed methods to execute the a cross-validation approach.\n\n## CV in `glmnet`\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncv.glmnet(x, # predictor matrix\n          y, # response variable\n          alpha, # Ridge\n          lambda, # Use a vector of lambdas\n          nfolds) # Number folds, use size of data for LOOCV\n```\n:::\n\n\n## Example - Ridge Regression\n\n\n::: panel-tabset\n## Preparation\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(glmnet)\nlibrary(tidyverse)\nlibrary(palmerpenguins)\npenguins <- penguins |> drop_na()\nmod <- penguins |> model.matrix(~ flipper_length_mm + bill_depth_mm + bill_length_mm - 1,\n  data = _) # Must include -1 to remove intercept, needed for glmnet\nlambdas <- seq(1,1000, by = 0.1)\n```\n:::\n\n\n\n## CV\n\n\n::: {.cell}\n\n```{.r .cell-code}\nridge_mod_cv <- cv.glmnet(x = mod, \n                          y = penguins$body_mass_g,\n                          alpha = 0,\n                          lambda = lambdas,\n                          nfolds = 333)\n```\n:::\n\n\n\n## CV Plot\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(ridge_mod_cv)\n```\n\n::: {.cell-output-display}\n![](11b_files/figure-revealjs/unnamed-chunk-4-1.png){width=960}\n:::\n:::\n\n\n\n\n## Best Parameter\n\n\n::: {.cell}\n\n```{.r .cell-code}\nridge_mod_cv$lambda.min\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> [1] 1.8\n```\n\n\n:::\n:::\n\n\n## Results\n\n\n::: {.cell}\n\n```{.r .cell-code}\nridge_mod <- glmnet(x = mod, \n                       y = penguins$body_mass_g,\n                       alpha = 0,\n                       lambda = 1.8)\n\ncoef(ridge_mod)[,1]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>       (Intercept) flipper_length_mm     bill_depth_mm    bill_length_mm \n#>      -6384.278567         50.452983         16.803642          3.716981\n```\n\n\n:::\n:::\n\n\n:::\n\n\n## Example - LASSO\n\n::: panel-tabset\n## Preparation\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(glmnet)\nlibrary(tidyverse)\nlibrary(palmerpenguins)\npenguins <- penguins |> drop_na()\nmod <- penguins |> model.matrix(~ flipper_length_mm + bill_depth_mm + bill_length_mm - 1,\n  data = _) # Must include -1 to remove intercept, needed for glmnet\nlambdas <- seq(1,1000, by = 0.1)\n```\n:::\n\n\n\n## CV\n\n\n::: {.cell}\n\n```{.r .cell-code}\nridge_mod_cv <- cv.glmnet(x = mod, \n                          y = penguins$body_mass_g,\n                          alpha = 1,\n                          lambda = lambdas,\n                          nfolds = 333)\n```\n:::\n\n\n\n## CV Plot\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(ridge_mod_cv)\n```\n\n::: {.cell-output-display}\n![](11b_files/figure-revealjs/unnamed-chunk-9-1.png){width=960}\n:::\n:::\n\n\n\n\n## Best Parameter\n\n\n::: {.cell}\n\n```{.r .cell-code}\nridge_mod_cv$lambda.min\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> [1] 1\n```\n\n\n:::\n:::\n\n\n## Results\n\n\n::: {.cell}\n\n```{.r .cell-code}\nridge_mod <- glmnet(x = mod, \n                       y = penguins$body_mass_g,\n                       alpha = 1,\n                       lambda = 1)\n\ncoef(ridge_mod)[,1]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>       (Intercept) flipper_length_mm     bill_depth_mm    bill_length_mm \n#>      -6388.713373         50.581044         16.602520          3.311258\n```\n\n\n:::\n:::\n\n\n:::\n\n## Try with `mtcars`\n\nComplete a LASSO approach using `mtcars` to predict mpg from the remaining variables.\n\n# Bootstrap Methods\n\n## Bootstrap Methods\n\nBootstrapping methods are used when we cannot theoretically compute the standard errors. Bootstrap methods are computationally intensive but will compute accurate standard errors.\n\nWhen all else fails, a bootstrap approach will compute accurate standard errors.\n\n## Bootstrap Algorithm\n\n1.  Draw a sample $X*$ of size $n$ with replacement from the original data $X$.\n    1.  $n$ is the size of the data\n2.  Compute the bootstrap replicate statistic $T* = g(X*)$, where $g(\\cdot)$ is the function that computes the statistic of interest.\n3.  Repeat steps 1-2 $B$ times to obtain $B$ bootstrap replicates ${T*_1, T*_2, ..., T*_B}$.\n4.  The computed statistics from $B$ samples are the empirical bootstrap distribution of the statistic, $g(X)$.\n5.  Calculate the bootstrap standard error of the statistic, $se_b(g(X))$, as the standard deviation of the bootstrap replicates.\n6.  Calculate the bootstrap confidence interval for the statistic, $CI(g(X))$, with the $\\alpha$ and $(1-\\alpha)%$ percentiles of the bootstrap replicates, where $\\alpha$ is the desired level of significance.\n\n## Examples\n\nFitting the following model:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(palmerpenguins)\nlibrary(tidyverse)\npenguins <- penguins |> drop_na()\npenguins |> lm(body_mass_g ~ flipper_length_mm + bill_length_mm + bill_depth_mm,\n               data = _)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> \n#> Call:\n#> lm(formula = body_mass_g ~ flipper_length_mm + bill_length_mm + \n#>     bill_depth_mm, data = penguins)\n#> \n#> Coefficients:\n#>       (Intercept)  flipper_length_mm     bill_length_mm      bill_depth_mm  \n#>         -6445.476             50.762              3.293             17.836\n```\n\n\n:::\n:::\n\n\nObtain the Bootstrap-based Standard Errors for the regression coefficients. Use $B=1000$ bootstrap samples.\n",
    "supporting": [
      "11b_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}