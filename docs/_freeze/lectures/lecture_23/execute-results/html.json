{
  "hash": "3392befc1166475761cc09960f66f187",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Bayes Classifier\"\nformat:\n  revealjs:\n    scrollable: true\n    navigation-mode: vertical\n    controls-layout: bottom-right\n    controls-tutorial: true\n    incremental: false \n    chalkboard:\n      src: chalkboard.json\n      storage: chalkboard_pres\n      theme: whiteboard\n      chalk-width: 4\nknitr:\n  opts_chunk: \n    echo: true\n    eval: true\n    message: false\n    warnings: false\n    comment: \"#>\" \n    \nrevealjs-plugins:\n  - pointer\n  - verticator\n  \nfilters: \n  - reveal-header\n  - code-fullscreen\n\neditor: visual\n---\n\n\n## Learning Outcomes\n\n-   Bayes Classifier\n\n-   Linear Discriminant Analysis\n\n-   Quadratic Discriminant Analysis\n\n-   Naive Bayes\n\n-   R Code\n\n# Bayes Classifier\n\n## Bayes Classifier\n\nBayes Classifier is used to classify a data point to a category $c$, given a set of predictors $\\boldsymbol x$\n\n$$\n\\Delta(\\boldsymbol x) = argmax_{k \\in K} f_k(c_k|\\boldsymbol X)\n$$\n\n-   $c_1, c_2,\\ldots, c_K$: Categories\n\n-   $f_k(c_k|\\boldsymbol X)$: conditional density function of $c_k$ given $\\boldsymbol X$\n\n## Probability\n\n$$\nf_k(c_k|\\boldsymbol X ) = \\frac{f_k(\\boldsymbol X)\\pi_c}{f(\\boldsymbol X)}\n$$\n\n-   $f_k(\\boldsymbol X)$: conditional density of $\\boldsymbol X$ given $c_k$\n\n-   $\\pi_k$: probability of observing $c_k$\n\n-   $f(\\boldsymbol X)$: probability density function of $\\boldsymbol X$\n\n# Linear Discriminant Analysis\n\n## LDA\n\nLinear Discriminant Analysis is used to classify a new data point, from a set of classifications, given information from a set of predictors.\n\nLDA classifies data using a Bayes classifier and imposing a normal distribution to the model.\n\n## LDA (p=1)\n\n$$\nf_k(\\boldsymbol X) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\exp\\left\\{\\frac{(x-\\mu_k)^2}{2\\sigma^2}\\right\\}\n$$\n\n$$\nf(X) = \\sum^K_{l=1} \\pi_l f_l(X)\n$$\n\n## LDA (p=1)\n\n$$\n\\delta_k = f_k(c_k|\\boldsymbol X ) = \\frac{f_k(\\boldsymbol X)\\pi_c}{f(\\boldsymbol X)}\n$$\n\n$$\n\\delta_k(x) = x\\frac{\\mu_k}{\\sigma^2}-\\frac{\\mu_k^2}{\\sigma^2} + \\ln(\\pi_k) \n$$\n\n## LDA (p=1) Estimates\n\nLet $Y_i=c_l$, $l=1\\ldots, K$, and $X_i=x_i$ bet the data from n observations:\n\n$$\n\\hat\\mu_k = \\frac{1}{n_k}\\sum^n_{i=1(Y_i=c_k)} x_i\n$$\n\n$$\n\\hat\\sigma^2=\\frac{1}{n-K}\\sum^K_{l=1}\\sum_{i=1(Y_i=c_l)}^n(x_i-\\hat\\mu_l)^2 \n$$\n\n-   $n_k$: number of observations in class $k$\n\n## LDA (p\\>1)\n\n$$\nf_k(\\boldsymbol X) = \\frac{1}{(2\\pi)^{p/2}|\\Sigma|^{1/2}}\\exp\\left\\{(\\boldsymbol x-\\boldsymbol{\\mu_k})^{\\mathrm T}\\Sigma^{-1}(\\boldsymbol x-\\boldsymbol \\mu_k)\\right\\}\n$$\n\n$$\nf(\\boldsymbol X) = \\sum^K_{l=1} \\pi_l f_l(\\boldsymbol X)\n$$\n\n## LDA (p\\>1)\n\n$$\n\\delta_k(\\boldsymbol x) = \\boldsymbol x^{\\mathrm T}\\Sigma^{-1}\\boldsymbol \\mu_k-\\frac{1}{2}\\boldsymbol \\mu_k^{\\mathrm T}\\Sigma^{-1}\\boldsymbol \\mu_k + \\ln(\\pi_k) \n$$\n\n## LDA Classification\n\nClassify each new data point as class $c_k$ based on the largest $\\delta_k(\\boldsymbol X)$.\n\n# Quadratic Discriminant Analysis\n\n## QDA\n\nIn LDA, it is assumed that $\\Sigma$ from $\\boldsymbol X$ is the same for all classification groups. In Quadratic Discriminant Analysis, this assumption is relaxed, resulting in $\\Sigma_k$ for each classification.\n\n## QDA\n\n$$\nf_k(\\boldsymbol X) = \\frac{1}{(2\\pi)^{p/2}|\\Sigma|^{1/2}}\\exp\\left\\{(\\boldsymbol x-\\boldsymbol{\\mu_k})^{\\mathrm T}\\Sigma_k^{-1}(\\boldsymbol x-\\boldsymbol \\mu_k)\\right\\}\n$$\n\n## QDA\n\n$$\n\\delta_k(\\boldsymbol x) = -\\frac{1}{2}\\boldsymbol x^{\\mathrm T}\\Sigma^{-1}\\boldsymbol x + \\boldsymbol x^{\\mathrm T}\\Sigma_k^{-1}\\boldsymbol \\mu_k-\\frac{1}{2}\\boldsymbol \\mu_k^{\\mathrm T}\\Sigma_k^{-1}\\boldsymbol \\mu_k - \\frac{1}{2}\\ln|\\Sigma_k| + \\ln(\\pi_k) \n$$\n\n# Naive Bayes\n\n## Naive Bayes\n\nA Naive Bayes classifier, assumes the predictors in $\\boldsymbol X$ are independent of each other.\n\n## Naive Bayes\n\n$$\nf_k(\\boldsymbol X) = \\prod^p_{j} f_{jk}(x_j|c_k)\n$$\n\n## Naive Bayes\n\n::: columns\n::: {.column width=\"50%\"}\n### Quantitative\n\n-   Normal: $N(\\mu_{jk}, \\sigma^2_{jk})$\n\n-   Nonparametric\n\n    -   Kernel Density\n:::\n\n::: {.column width=\"50%\"}\n### Qualitative\n\n-   Nonparametric\n:::\n:::\n\n# R Code\n\n## LDA\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(palmerpenguins)\nlibrary(MASS)\nlibrary(tidyverse)\nlibrary(magrittr)\n\npenguins_df <- penguins %>% drop_na\nx_lda <- penguins_df %$% lda(species ~ bill_length_mm + \n                                       bill_depth_mm + \n                                       flipper_length_mm + \n                                       body_mass_g)\n```\n:::\n\n\n## LDA Prediction\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnew_df <- penguins_df %>% select(bill_length_mm, \n                                 bill_depth_mm,\n                                 flipper_length_mm,\n                                 body_mass_g)\nx_lda_predict <- x_lda %>% predict(new_df)\n```\n:::\n\n\n## LDA Confusion Matrix\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntable(penguins_df$species, x_lda_predict$class)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>            \n#>             Adelie Chinstrap Gentoo\n#>   Adelie       145         1      0\n#>   Chinstrap      3        65      0\n#>   Gentoo         0         0    119\n```\n\n\n:::\n:::\n\n\n## QDA\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx_qda <- penguins_df %$% qda(species ~ bill_length_mm + \n                                       bill_depth_mm + \n                                       flipper_length_mm + \n                                       body_mass_g)\n```\n:::\n\n\n## QDA Prediction\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx_qda_predict <- x_qda %>% predict(penguins_df %>% \n                                     select(bill_length_mm, \n                                            bill_depth_mm,\n                                            flipper_length_mm,\n                                            body_mass_g))\n```\n:::\n\n\n## QDA Confusion Matrix\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntable(penguins_df$species, x_qda_predict$class)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>            \n#>             Adelie Chinstrap Gentoo\n#>   Adelie       144         2      0\n#>   Chinstrap      2        66      0\n#>   Gentoo         0         0    119\n```\n\n\n:::\n:::\n\n\n## Naive Bayes\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(e1071)\nx_nb <- penguins_df %>% naiveBayes(species ~ bill_length_mm +\n                                             bill_depth_mm + \n                                             flipper_length_mm + \n                                             body_mass_g, .)\n```\n:::\n\n\n## Naive Bayes Prediction\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx_nb_predict <- x_nb %>% predict(penguins_df %>% \n                                     select(bill_length_mm, \n                                            bill_depth_mm,\n                                            flipper_length_mm,\n                                            body_mass_g))\n```\n:::\n\n\n## Naive Bayes Confusion Matrix\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntable(penguins_df$species, x_nb_predict)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>            x_nb_predict\n#>             Adelie Chinstrap Gentoo\n#>   Adelie       141         5      0\n#>   Chinstrap      5        63      0\n#>   Gentoo         0         0    119\n```\n\n\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}