{
  "hash": "cd872ebeccd427ef81ade364f48b90fd",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: |\n  Convolutional \\\n  Neural Networks\nsubtitle: \"Image Classification\"\nformat:\n  revealjs:\n    scrollable: true\n    navigation-mode: vertical\n    controls-layout: bottom-right\n    controls-tutorial: true\n    incremental: false \n    chalkboard:\n      src: chalkboard.json\n      storage: chalkboard_pres\n      theme: whiteboard\n      chalk-width: 4\nknitr:\n  opts_chunk: \n    echo: true\n    eval: true\n    message: false\n    warnings: false\n    comment: \"#>\" \n    \nrevealjs-plugins:\n  - pointer\n  - verticator\n  \nfilters: \n  - reveal-header\n  - code-fullscreen\n  - reveal-auto-agenda\n\neditor: source\n---\n\n\n# Convolutional Neural Networks\n\n## Convolutional Neural Networks\n\n# Convolutional Layers\n\n# Pooling Layers\n\n# R Code\n\n## MNIST\n\nThis is a database of handwritten digits.\n\nWe will use to construct neural networks that will classify images.\n\n## Installation of Torch\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninstall.packages(\"torch\")\ninstall.packages(\"luz\")\ninstall.packages(\"torchvision\")\ninstall.packages(\"torchdatasets\")\ninstall.packages(\"zeallot\")\n```\n:::\n\n\n## Torch Packages in R\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# \nlibrary(torch)\nlibrary(luz) # high-level interface for torch\nlibrary(torchvision) # for datasets and image transformation\nlibrary(torchdatasets) # for datasets we are going to use\nlibrary(zeallot)\ntorch_manual_seed(13)\n```\n:::\n\n\n\n## MNIST\n\n\n::: {.cell}\n\n```{.r .cell-code}\n###\ntrain_ds <- mnist_dataset(root = \".\", train = TRUE, download = TRUE)\ntest_ds <- mnist_dataset(root = \".\", train = FALSE, download = TRUE)\n\ntrain_ds[1]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> $x\n#>       [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13]\n#>  [1,]    0    0    0    0    0    0    0    0    0     0     0     0     0\n#>  [2,]    0    0    0    0    0    0    0    0    0     0     0     0     0\n#>  [3,]    0    0    0    0    0    0    0    0    0     0     0     0     0\n#>  [4,]    0    0    0    0    0    0    0    0    0     0     0     0     0\n#>  [5,]    0    0    0    0    0    0    0    0    0     0     0     0     0\n#>  [6,]    0    0    0    0    0    0    0    0    0     0     0     0     3\n#>  [7,]    0    0    0    0    0    0    0    0   30    36    94   154   170\n#>  [8,]    0    0    0    0    0    0    0   49  238   253   253   253   253\n#>  [9,]    0    0    0    0    0    0    0   18  219   253   253   253   253\n#> [10,]    0    0    0    0    0    0    0    0   80   156   107   253   253\n#> [11,]    0    0    0    0    0    0    0    0    0    14     1   154   253\n#> [12,]    0    0    0    0    0    0    0    0    0     0     0   139   253\n#> [13,]    0    0    0    0    0    0    0    0    0     0     0    11   190\n#> [14,]    0    0    0    0    0    0    0    0    0     0     0     0    35\n#> [15,]    0    0    0    0    0    0    0    0    0     0     0     0     0\n#> [16,]    0    0    0    0    0    0    0    0    0     0     0     0     0\n#> [17,]    0    0    0    0    0    0    0    0    0     0     0     0     0\n#> [18,]    0    0    0    0    0    0    0    0    0     0     0     0     0\n#> [19,]    0    0    0    0    0    0    0    0    0     0     0     0     0\n#> [20,]    0    0    0    0    0    0    0    0    0     0     0     0    39\n#> [21,]    0    0    0    0    0    0    0    0    0     0    24   114   221\n#> [22,]    0    0    0    0    0    0    0    0   23    66   213   253   253\n#> [23,]    0    0    0    0    0    0   18  171  219   253   253   253   253\n#> [24,]    0    0    0    0   55  172  226  253  253   253   253   244   133\n#> [25,]    0    0    0    0  136  253  253  253  212   135   132    16     0\n#> [26,]    0    0    0    0    0    0    0    0    0     0     0     0     0\n#> [27,]    0    0    0    0    0    0    0    0    0     0     0     0     0\n#> [28,]    0    0    0    0    0    0    0    0    0     0     0     0     0\n#>       [,14] [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22] [,23] [,24] [,25]\n#>  [1,]     0     0     0     0     0     0     0     0     0     0     0     0\n#>  [2,]     0     0     0     0     0     0     0     0     0     0     0     0\n#>  [3,]     0     0     0     0     0     0     0     0     0     0     0     0\n#>  [4,]     0     0     0     0     0     0     0     0     0     0     0     0\n#>  [5,]     0     0     0     0     0     0     0     0     0     0     0     0\n#>  [6,]    18    18    18   126   136   175    26   166   255   247   127     0\n#>  [7,]   253   253   253   253   253   225   172   253   242   195    64     0\n#>  [8,]   253   253   253   253   251    93    82    82    56    39     0     0\n#>  [9,]   253   198   182   247   241     0     0     0     0     0     0     0\n#> [10,]   205    11     0    43   154     0     0     0     0     0     0     0\n#> [11,]    90     0     0     0     0     0     0     0     0     0     0     0\n#> [12,]   190     2     0     0     0     0     0     0     0     0     0     0\n#> [13,]   253    70     0     0     0     0     0     0     0     0     0     0\n#> [14,]   241   225   160   108     1     0     0     0     0     0     0     0\n#> [15,]    81   240   253   253   119    25     0     0     0     0     0     0\n#> [16,]     0    45   186   253   253   150    27     0     0     0     0     0\n#> [17,]     0     0    16    93   252   253   187     0     0     0     0     0\n#> [18,]     0     0     0     0   249   253   249    64     0     0     0     0\n#> [19,]     0    46   130   183   253   253   207     2     0     0     0     0\n#> [20,]   148   229   253   253   253   250   182     0     0     0     0     0\n#> [21,]   253   253   253   253   201    78     0     0     0     0     0     0\n#> [22,]   253   253   198    81     2     0     0     0     0     0     0     0\n#> [23,]   195    80     9     0     0     0     0     0     0     0     0     0\n#> [24,]    11     0     0     0     0     0     0     0     0     0     0     0\n#> [25,]     0     0     0     0     0     0     0     0     0     0     0     0\n#> [26,]     0     0     0     0     0     0     0     0     0     0     0     0\n#> [27,]     0     0     0     0     0     0     0     0     0     0     0     0\n#> [28,]     0     0     0     0     0     0     0     0     0     0     0     0\n#>       [,26] [,27] [,28]\n#>  [1,]     0     0     0\n#>  [2,]     0     0     0\n#>  [3,]     0     0     0\n#>  [4,]     0     0     0\n#>  [5,]     0     0     0\n#>  [6,]     0     0     0\n#>  [7,]     0     0     0\n#>  [8,]     0     0     0\n#>  [9,]     0     0     0\n#> [10,]     0     0     0\n#> [11,]     0     0     0\n#> [12,]     0     0     0\n#> [13,]     0     0     0\n#> [14,]     0     0     0\n#> [15,]     0     0     0\n#> [16,]     0     0     0\n#> [17,]     0     0     0\n#> [18,]     0     0     0\n#> [19,]     0     0     0\n#> [20,]     0     0     0\n#> [21,]     0     0     0\n#> [22,]     0     0     0\n#> [23,]     0     0     0\n#> [24,]     0     0     0\n#> [25,]     0     0     0\n#> [26,]     0     0     0\n#> [27,]     0     0     0\n#> [28,]     0     0     0\n#> \n#> $y\n#> [1] 6\n```\n\n\n:::\n\n```{.r .cell-code}\n# test_ds[2]\n```\n:::\n\n\n\n  ## Transforming Data\n\nIn order to use torch, you must transform the data:\n-   tensor\n-   flatten\n-   tensor divided by the potential values (255)\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n###\ntransform <- function(x) {\n  x |>\n    torch_tensor()  |>\n    torch_flatten() |>\n    torch_div(255)\n}\ntrain_ds <- mnist_dataset(\n  root = \".\",\n  train = TRUE,\n  download = TRUE,\n  transform = transform\n)\ntest_ds <- mnist_dataset(\n  root = \".\",\n  train = FALSE,\n  download = TRUE,\n  transform = transform\n)\n```\n:::\n\n\n\n## Neural Network Model Set Up\n\nThe `nn_module` will begin to setup the neural network. It requires the `initialize` and `forward` functions.\n\n::: fragment\n`initialize` is a function that describes the elements of the neural network, the layers.\n:::\n\n\n::: fragment\n`nn_linear` will construct a linear framework for the number of inputs, and the number of outputs in the neural network.\n:::\n\n::: fragment\n`nn_dropout` will randomly \"zero\" an input elements of a tensor with probability `p`.\n:::\n\n::: fragment\n`nn_relu` specifies the linear unit function\n:::\n\n::: fragment\n`forward` describes how the neural network is formatted using the values from the `initialize` function.\n:::\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n###\nmodelnn <- nn_module(\n  initialize = function() {\n    self$linear1 <- nn_linear(in_features = 28*28, out_features = 256)\n    self$linear2 <- nn_linear(in_features = 256, out_features = 128)\n    self$linear3 <- nn_linear(in_features = 128, out_features = 10)\n\n    self$drop1 <- nn_dropout(p = 0.4)\n    self$drop2 <- nn_dropout(p = 0.3)\n\n    self$activation <- nn_relu()\n  },\n  forward = function(x) {\n    x |>\n      self$linear1() |>\n      self$activation() |>\n      self$drop1() |>\n\n      self$linear2() |>\n      self$activation() |>\n      self$drop2() |>\n      self$linear3()\n  }\n)\n\n## Describe the model:\nprint(modelnn())\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> An `nn_module` containing 235,146 parameters.\n#> \n#> ── Modules ─────────────────────────────────────────────────────────────────────\n#> • linear1: <nn_linear> #200,960 parameters\n#> • linear2: <nn_linear> #32,896 parameters\n#> • linear3: <nn_linear> #1,290 parameters\n#> • drop1: <nn_dropout> #0 parameters\n#> • drop2: <nn_dropout> #0 parameters\n#> • activation: <nn_relu> #0 parameters\n```\n\n\n:::\n:::\n\n\n## Set Up Neural Network\n\nTells `luz` (`torch`) how to execute the neural network.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodelnn <- modelnn |>\n  setup(\n    loss = nn_cross_entropy_loss(),\n    optimizer = optim_rmsprop,\n    metrics = list(luz_metric_accuracy())\n  )\n```\n:::\n\n\n## Fit the Neural Network\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsystem.time(\n   fitted <- modelnn |>\n      fit(\n        data = train_ds,\n        epochs = 5,\n        valid_data = 0.2,\n        dataloader_options = list(batch_size = 256),\n        verbose = FALSE\n      )\n )\nplot(fitted)\n```\n:::\n\n\n\n## Test Efficiency of Neural Network\n\n\n::: {.cell}\n\n```{.r .cell-code}\naccuracy <- function(pred, truth) {\n   mean(pred == truth) }\n\n# gets the true classes from all observations in test_ds.\ntruth <- sapply(seq_along(test_ds), function(x) test_ds[x][[2]])\n\nfitted |>\n  predict(test_ds) |>\n  torch_argmax(dim = 2) |> # the predicted class is the one with higher 'logit'.\n  as_array() |>  # convert to an R object\n  accuracy(truth) # use function created\n```\n:::",
    "supporting": [
      "14b_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}