{
  "hash": "ca00c6b785680fba36737c91622bd7f7",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Nonparametric Regression\"\nformat:\n  revealjs:\n    scrollable: true\n    navigation-mode: vertical\n    controls-layout: bottom-right\n    controls-tutorial: true\n    incremental: false \n    chalkboard:\n      src: chalkboard.json\n      storage: chalkboard_pres\n      theme: whiteboard\n      chalk-width: 4\nknitr:\n  opts_chunk: \n    echo: true\n    eval: true\n    message: false\n    warnings: false\n    comment: \"#>\" \n    \nrevealjs-plugins:\n  - pointer\n  - verticator\n  \nfilters: \n  - reveal-header\n  - code-fullscreen\n\neditor: visual\n---\n\n\n## Learning Outcomes\n\n-   LASSO\n\n-   Regression Splines\n\n-   Smoothing Splines\n\n-   Generalized Additive Models\n\n# Cross-Validation\n\n## Cross-Validation\n\nA cross-validation approach is to obtain a good estimate of the error-rate of a machine learning algorithm. We split the data set into two categories: training and testing. The training data set is used to train the model, and the test data is used to test the model and compute the error rate.\n\n## Tuning Parameter\n\nA cross-validation approach is great when there is a tuning parameter. We can fit a model for different values of the tuning parameter, and we can choose which value results in the lowest error rate.\n\n## LOOCV Cross-Validation\n\n-   Choose a set of tuning parameters to test.\n\n-   For each $k$th turning parameter Calculate the tuning parameter error for each value\n\n    -   Utilize the leave-one-out approach\n\n        -   For each observation fit a model with the remaining observations and fit the excluded value\n\n        -   Compute the following error:\n\n            $$\n            CVE_k = \\frac{1}{n}\\sum^n_{i=1}e_i \n            $$\n\n-   Identify the $k$th tuning parameter with the lowest $CVE_k$\n\n## K-Fold Cross-Validation\n\n-   Choose a set of tuning parameters to test.\n\n-   Create different K subsets of the data.\n\n-   For each $j$th turning parameter Calculate the tuning parameter error for each value\n\n    -   For each K subset, fit a model using the data excluding the Kth subset\n\n    -   Predict the values in the Kth subset using the fitted model\n\n    -   Repeat the process for each K subset\n\n    -   Compute the following error:\n\n        $$\n        CVE_j = \\frac{1}{n}\\sum^n_{i=1}e_i \n        $$\n\n-   Identify the $j$th tuning parameter with the lowest $CVE_j$\n\n# Bootstrap Methods\n\n## Bootstrap Methods\n\nBootstrapping methods are used when we cannot theoretically compute the standard errors. Bootstrap methods are computationally intensive but will compute accurate standard errors.\n\nWhen all else fails, a bootstrap approach will compute accurate standard errors.\n\n## Bootstrap Algorithm\n\n1.  Draw a sample $X*$ of size $n$ with replacement from the original data $X$.\n    1.  $n$ is the size of the data\n2.  Compute the bootstrap replicate statistic $T* = g(X*)$, where $g(\\cdot)$ is the function that computes the statistic of interest.\n3.  Repeat steps 1-2 $B$ times to obtain $B$ bootstrap replicates ${T*_1, T*_2, ..., T*_B}$.\n4.  The computed statistics from $B$ samples are the empirical bootstrap distribution of the statistic, $g(X)$.\n5.  Calculate the bootstrap standard error of the statistic, $se_b(g(X))$, as the standard deviation of the bootstrap replicates.\n6.  Calculate the bootstrap confidence interval for the statistic, $CI(g(X))$, with the $\\alpha$ and $(1-\\alpha)%$ percentiles of the bootstrap replicates, where $\\alpha$ is the desired level of significance.\n\n## Examples\n\nFitting the following model:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(palmerpenguins)\nlibrary(tidyverse)\nlibrary(magrittr)\npenguins <- penguins %>% drop_na()\npenguins %$% lm(body_mass_g ~ flipper_length_mm + bill_length_mm + bill_depth_mm)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> \n#> Call:\n#> lm(formula = body_mass_g ~ flipper_length_mm + bill_length_mm + \n#>     bill_depth_mm)\n#> \n#> Coefficients:\n#>       (Intercept)  flipper_length_mm     bill_length_mm      bill_depth_mm  \n#>         -6445.476             50.762              3.293             17.836\n```\n\n\n:::\n:::\n\n\nObtain the Bootstrap-based Standard Errors. Use $B=1000$ bootstrap samples.\n",
    "supporting": [
      "11a_files/figure-revealjs"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}