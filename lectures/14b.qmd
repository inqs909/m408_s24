---
title: |
  Convolutional \
  Neural Networks
subtitle: "Image Classification"
format:
  revealjs:
    scrollable: true
    navigation-mode: vertical
    controls-layout: bottom-right
    controls-tutorial: true
    incremental: false 
    chalkboard:
      src: chalkboard.json
      storage: chalkboard_pres
      theme: whiteboard
      chalk-width: 4
knitr:
  opts_chunk: 
    echo: true
    eval: true
    message: false
    warnings: false
    comment: "#>" 
    
revealjs-plugins:
  - pointer
  - verticator
  
filters: 
  - reveal-header
  - code-fullscreen
  - reveal-auto-agenda

editor: source
---

# Convolutional Neural Networks

## Convolutional Neural Networks

Convolutional Neural Networks were developed in terms of image analysis.

::: fragment
The idea is to mimic how a human minds will classify an image.
:::

::: fragment
A convolutional neural networks is trained by using a set of images that have been previously classfied.
:::

::: fragment
Once the network is trained, we can give new types of images to be classified.
:::

## Convolutiona Neural Networks

![](img/squirrel.jpg){fig-align="center"}

## Convolutional Neural Networks

A CNN will identify certain features, arrange them, and match them to what is closely is known.

## CNN

![Credit: ISLR2](img/islr2/Chapter10/10_6.jpg){fig-align="center"}

# Layers

## Convolution Filter

A Convolution Filter will highlight certain features of an image.

::: fragment
The matching features will contain a large value.
:::

::: fragment
Dismatching features will contain a smaller value.
:::

## Convolution Filter

::: panel-tabset
## Image

$$
\left(
\begin{array}{ccc}
a & b & c \\
d & e & f \\
g & h & i \\
j & k & l 
\end{array}
\right)
$$

## Filter

$$
\left(
\begin{array}{cc}
\alpha & \beta \\
\gamma & \delta
\end{array}
\right)
$$

## Both

$$
\left(
\begin{array}{ccc}
a & b & c \\
d & e & f \\
g & h & i \\
j & k & l 
\end{array}
\right)
*
\left(
\begin{array}{cc}
\alpha & \beta \\
\gamma & \delta
\end{array}
\right)
$$

## Results

$$
\left(
\begin{array}{cc}
a\alpha + b\beta + d\gamma + w\delta & b\alpha + c\beta + e\gamma + f\delta \\
d\alpha + e\beta + g\gamma + h\delta & e\alpha + f\beta + h\gamma + i\delta \\
g\alpha + h\beta + j\gamma + k\delta & h\alpha + i\beta + k\gamma + l\delta
\end{array}
\right)
$$
:::

## Convolutional Layers

Convolution layers are a set of filters in a hidden layers. We can have $K$ layers that an image is passed through.

## Pooling Layers

The act of summarizing a large matrix to a smaller matrix.

## Max Pool

$$
\left[
\begin{array}{cccc}
1 & 3 & 9 & 5 \\
6 & 2 & 3 & 4 \\
1 & 0 & 6 & 4 \\
8 & 4 & 2 & 7
\end{array}
\right] \rightarrow
\left[
\begin{array}{cc}
6 & 9 \\
8 & 7
\end{array}
\right]
$$

# Architecture

## Data Image

For each image, there are 3 channels (RGB) that represent the image.

::: fragment
Afterwards, the image is gridded up into pixels with each containing a 3-values (RGB).
:::

## Data Image

![](https://insightimi.wordpress.com/wp-content/uploads/2021/02/1_r2wi31-arzxihybbjd7luq.png?w=1024){fig-align="center"}

## Convolve Image

For each RGB channel, apply a set of convolution filters.

::: fragment
Then pool the filters.
:::

::: fragment
Repeat for next hidden layer.
:::

## Flattening

Once the images has been pooled to a select pixels or features. The images are flattened to a set of inputs.

::: fragment
These inputs are used to a traditional neural network to classify an image.
:::

## Architecture

![](https://www.embedded.com/wp-content/uploads/2023/06/23026adi-cnn1_f03_thumb.jpg){fig-align="center"}

## Training

The CNN is trained by supplying a set of pre-classified images.

::: fragment
The parameters in the convolution filters are estimates using standard techniques.
:::

## Data Augmentation

::: columns
::: {.column width="50%"}
![](img/squirrel.jpg)
:::

::: {.column width="50%"}
![](img/squirrel_mirror.jpg)
:::
:::

# R MNIST Code

## MNIST

This is a database of handwritten digits.

We will use to construct neural networks that will classify images.

## Torch Packages in R

```{r}
#| echo: true
#| eval: true

library(torch)
library(luz) # high-level interface for torch
library(torchvision) # for datasets and image transformation
library(torchdatasets) # for datasets we are going to use
library(zeallot)
torch_manual_seed(13)

```

## MNIST

```{r}
#| echo: true
#| eval: true
###
train_ds <- mnist_dataset(root = ".", train = TRUE, download = TRUE)
test_ds <- mnist_dataset(root = ".", train = FALSE, download = TRUE)

train_ds[1]
# test_ds[2]

```

## Transforming Data

In order to use torch, you must transform the data: - tensor - flatten - tensor divided by the potential values (255)

```{r}
#| echo: true
#| eval: true
 
###
transform <- function(x) {
  x |>
    torch_tensor()  |>
    torch_flatten() |>
    torch_div(255)
}
train_ds <- mnist_dataset(
  root = ".",
  train = TRUE,
  download = TRUE,
  transform = transform
)
test_ds <- mnist_dataset(
  root = ".",
  train = FALSE,
  download = TRUE,
  transform = transform
)

```

## Neural Network Model Set Up

The `nn_module` will begin to setup the neural network. It requires the `initialize` and `forward` functions.

::: fragment
`initialize` is a function that describes the elements of the neural network, the layers.
:::

::: fragment
`nn_linear` will construct a linear framework for the number of inputs, and the number of outputs in the neural network.
:::

::: fragment
`nn_dropout` will randomly "zero" an input elements of a tensor with probability `p`.
:::

::: fragment
`nn_relu` specifies the linear unit function
:::

::: fragment
`forward` describes how the neural network is formatted using the values from the `initialize` function.
:::

```{r}
#| echo: true
#| eval: true

###
modelnn <- nn_module(
  initialize = function() {
    self$linear1 <- nn_linear(in_features = 28*28, out_features = 256)
    self$linear2 <- nn_linear(in_features = 256, out_features = 128)
    self$linear3 <- nn_linear(in_features = 128, out_features = 10)

    self$drop1 <- nn_dropout(p = 0.4)
    self$drop2 <- nn_dropout(p = 0.3)

    self$activation <- nn_relu()
  },
  forward = function(x) {
    x |>
      self$linear1() |>
      self$activation() |>
      self$drop1() |>

      self$linear2() |>
      self$activation() |>
      self$drop2() |>
      self$linear3()
  }
)


```

## Set Up Neural Network

Tells `luz` (`torch`) how to execute the neural network.

```{r}
#| echo: true
#| eval: true

modelnn <- modelnn |>
  setup(
    loss = nn_cross_entropy_loss(),
    optimizer = optim_rmsprop,
    metrics = list(luz_metric_accuracy())
  )
```

## Fit the Neural Network

::: panel-tabset
## Fitting

```{r}
#| echo: true
#| eval: true

system.time(
   fitted <- modelnn |>
      fit(
        data = train_ds,
        epochs = 5,
        valid_data = 0.2,
        dataloader_options = list(batch_size = 256),
        verbose = FALSE
      )
 )
```

## Plot

```{r}
plot(fitted)
```
:::

## Test Efficiency of Neural Network

```{r}
#| echo: true
#| eval: true


accuracy <- function(pred, truth) {
   mean(pred == truth) }

# gets the true classes from all observations in test_ds.
truth <- sapply(seq_along(test_ds), function(x) test_ds[x][[2]])

fitted |>
  predict(test_ds) |>
  torch_argmax(dim = 2) |> # the predicted class is the one with higher 'logit'.
  as_array() |>  # convert to an R object
  accuracy(truth) # use function created

```

# R Code CNN

## CIFAR Data

The CIFAR database contains 60,000 images labeled with 20 superclasses with 5 animals for each superclass.

## CIFAR Data

```{r}
#| echo: true
#| eval: true
transform <- function(x) {
  transform_to_tensor(x)
}

train_ds <- cifar100_dataset(
  root = "./", 
  train = TRUE, 
  download = TRUE, 
  transform = transform
)

test_ds <- cifar100_dataset(
  root = "./", 
  train = FALSE, 
  transform = transform
)

train_ds[1]

```

## Sample Image

```{r}
par(mar = c(0, 0, 0, 0), mfrow = c(2, 2))
index <- sample(seq(50000), 4)
for (i in index) plot(as.raster(as.array(train_ds[i][[1]]$permute(c(2,3,1)))))
```

## Defining CNN

::: panel-tabset
## Convulational Layers

```{r}
#| echo: true
#| eval: true
conv_block <- nn_module(
  initialize = function(in_channels, out_channels) {
    self$conv <- nn_conv2d(
      in_channels = in_channels, 
      out_channels = out_channels, 
      kernel_size = c(3,3),
      padding = "same"
    )
    self$relu <- nn_relu()
    self$pool <- nn_max_pool2d(kernel_size = c(2,2))
  },
  forward = function(x) {
    x |> 
      self$conv() |>  
      self$relu() |> 
      self$pool()
  }
)
```

-   `in_channels`: Number of inputs planes (3 at the beginning)
-   `out_channels`: Number of output planes (may vary)
-   `kernel_size`: convolutional filter size
-   `padding`: adds null values to images make the same
-   `nn_relu`: Use ReLU
-   `nn_max_pool2d`: Size Pooling Matrix

## NN

```{r}
#| echo: true
#| eval: true
model <- nn_module(
  initialize = function() {
    self$conv <- nn_sequential(
      conv_block(3, 32),
      conv_block(32, 64),
      conv_block(64, 128),
      conv_block(128, 256)
    )
    self$output <- nn_sequential(
      nn_dropout(0.5),
      nn_linear(2*2*256, 512),
      nn_relu(),
      nn_linear(512, 100)
    )
  },
  forward = function(x) {
    x |> 
      self$conv() |> 
      torch_flatten(start_dim = 2) |>
      self$output()
  }
)
```

-   `nn_sequential`: creates a sequence of functions
-   `conv_block`: defined previously
-   `Output`: Defines final neural network
-   `Forward`: Defines overall neural network

## Model

```{r}
#| echo: true
#| eval: true
model()
```
:::

## Fitting CNN

::: panel-tabset
## Fit

```{r}
#| eval: true
#| echo: true
system.time(
fitted <- model |>  
  setup(
    loss = nn_cross_entropy_loss(),
    optimizer = optim_rmsprop, 
    metrics = list(luz_metric_accuracy())
  ) |> 
  set_opt_hparams(lr = 0.001) |> 
  fit(
    train_ds,
    epochs = 10, #30,
    valid_data = 0.2,
    dataloader_options = list(batch_size = 128)
  )
)

```

## Summary

```{r}
#| eval: true
#| echo: true
print(fitted)
```

## Evaluate

```{r}
#| eval: true
#| echo: true
evaluate(fitted, test_ds)
```
:::

## Squirrel Image

Download labels json [here](https://github.com/MartinThoma/algorithms/blob/master/ML/confusion-matrix/labels/cifar-100-labels.json).

Download the squirrel image [here](https://m408.inqs.info/lectures/img/squirrel.jpg).

```{r}
#| eval: true
#| echo: false

cifar100_mapping <- jsonlite::read_json("data/cifar-100-labels.json")

x <- torch_empty(1, 3, 32, 32)
img_path <- file.path("img/squirrel.jpg")
img <- img_path |>  
  base_loader() |>  
  transform_to_tensor() |>  
  transform_resize(c(32, 32)) |>  
  # normalize with imagenet mean and stds.
  transform_normalize(
    mean = c(0.4914, 0.4822, 0.4465),
    std = c(0.2470, 0.2435, 0.2616)
  )
x[1,,, ] <- img


preds <- fitted |> 
  predict(x) |> 
  torch_topk(dim = 2, k = 100)

cifar100_mapping[as.integer(preds[[2]])]

```

## All R Code

```{r}
#| echo: true
#| eval: false

library(torch)
library(luz) # high-level interface for torch
library(torchvision) # for datasets and image transformation
library(torchdatasets) # for datasets we are going to use
library(zeallot)
torch_manual_seed(13)

transform <- function(x) {
  transform_to_tensor(x)
}

train_ds <- cifar100_dataset(
  root = "./", 
  train = TRUE, 
  download = TRUE, 
  transform = transform
)

test_ds <- cifar100_dataset(
  root = "./", 
  train = FALSE, 
  transform = transform
)

train_ds[1]
par(mar = c(0, 0, 0, 0), mfrow = c(2, 2))
index <- sample(seq(50000), 4)
for (i in index) plot(as.raster(as.array(train_ds[i][[1]]$permute(c(2,3,1)))))
conv_block <- nn_module(
  initialize = function(in_channels, out_channels) {
    self$conv <- nn_conv2d(
      in_channels = in_channels, 
      out_channels = out_channels, 
      kernel_size = c(3,3),
      padding = "same"
    )
    self$relu <- nn_relu()
    self$pool <- nn_max_pool2d(kernel_size = c(2,2))
  },
  forward = function(x) {
    x |> 
      self$conv() |>  
      self$relu() |> 
      self$pool()
  }
)
model <- nn_module(
  initialize = function() {
    self$conv <- nn_sequential(
      conv_block(3, 32),
      conv_block(32, 64),
      conv_block(64, 128),
      conv_block(128, 256)
    )
    self$output <- nn_sequential(
      nn_dropout(0.5),
      nn_linear(2*2*256, 512),
      nn_relu(),
      nn_linear(512, 100)
    )
  },
  forward = function(x) {
    x |> 
      self$conv() |> 
      torch_flatten(start_dim = 2) |>
      self$output()
  }
)

model()
system.time(
fitted <- model |>  
  setup(
    loss = nn_cross_entropy_loss(),
    optimizer = optim_rmsprop, 
    metrics = list(luz_metric_accuracy())
  ) |> 
  set_opt_hparams(lr = 0.001) |> 
  fit(
    train_ds,
    epochs = 10, #30,
    valid_data = 0.2,
    dataloader_options = list(batch_size = 128)
  )
)

print(fitted)
evaluate(fitted, test_ds)

cifar100_mapping <- jsonlite::read_json("data/cifar-100-labels.json")

x <- torch_empty(1, 3, 32, 32)
img_path <- file.path("img/squirrel.jpg")
img <- img_path |>  
  base_loader() |>  
  transform_to_tensor() |>  
  transform_resize(c(32, 32)) |>  
  # normalize with imagenet mean and stds.
  transform_normalize(
    mean = c(0.4914, 0.4822, 0.4465),
    std = c(0.2470, 0.2435, 0.2616)
  )
x[1,,, ] <- img


preds <- fitted |> 
  predict(x) |> 
  torch_topk(dim = 2, k = 100)

cifar100_mapping[as.integer(preds[[2]])]
```



# R Code Pre-Trained CNN

## Pre-Trained CNN

Both Torch and Tensorflow has access to convolutional neural networks trained using the imagenet data base.

## Pre-Trained CNN

```{r}
#| eval: true
#| echo: true

model_imagenet <- torchvision::model_resnet18(pretrained = TRUE)
model_imagenet$eval() # put the model in evaluation mode

```

## Loading Images

Download book images [here](https://www.statlearning.com/s/book_images.zip).

```{r}
#| echo: true
#| eval: true
img_dir <- "img/books"
image_names <- list.files(img_dir)
num_images <- length(image_names)
x <- torch_empty(num_images, 3, 224, 224)
for (i in 1:num_images) {
   img_path <- file.path(img_dir, image_names[i])
   img <- img_path |> 
     base_loader() |>  
     transform_to_tensor() |>  
     transform_resize(c(224, 224)) |>  
     # normalize with imagenet mean and stds.
     transform_normalize(
       mean = c(0.485, 0.456, 0.406),
       std = c(0.229, 0.224, 0.225)
     )
   x[i,,, ] <- img
}
```

## Prediction

::: {.panel-tabset}

## Prediction

```{r}
#| echo: true
#| eval: true
preds <- model_imagenet(x)
top3 <- torch_topk(preds, dim = 2, k = 3)
```

## Labels

```{r}
#| echo: true
#| eval: true
mapping <- jsonlite::read_json("https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json") |> 
  sapply(function(x) x[[2]])
```

## Labeling

```{r}
#| echo: true
#| eval: true
top3_prob <- top3[[1]] |> 
  nnf_softmax(dim = 2) |> 
  torch_unbind() |> 
  lapply(as.numeric)

top3_class <- top3[[2]] |> 
  torch_unbind() |> 
  lapply(function(x) mapping[as.integer(x)])

result <- purrr::map2(top3_prob, top3_class, function(pr, cl) {
  names(pr) <- cl
  pr
})
names(result) <- image_names

```
## Results

```{r}
#| echo: true
#| eval: true


print(result)
```

  
:::


## Squirrel

::: {.panel-tabset}

## Reload Image

```{r}
#| echo: true
#| eval: true

x <- torch_empty(1, 3, 224, 224)
img_path <- file.path("img/squirrel.jpg")
img <- img_path |>  
  base_loader() |>  
  transform_to_tensor() |>  
  transform_resize(c(224, 224)) |>  
  # normalize with imagenet mean and stds.
     transform_normalize(
       mean = c(0.485, 0.456, 0.406),
       std = c(0.229, 0.224, 0.225)
     )
x[1,,, ] <- img

```
## Results

```{r}
#| echo: true
#| eval: true


preds <- model_imagenet(x)
top3 <- torch_topk(preds, dim = 2, k = 3)
mapping[as.integer(top3[[2]])]

```

:::


## ALL R Code

```{r}
#| echo: true
#| eval: false

library(torch)
library(luz) # high-level interface for torch
library(torchvision) # for datasets and image transformation
library(torchdatasets) # for datasets we are going to use
library(zeallot)
torch_manual_seed(13)

img_dir <- "img/books" ## CHANGE THIS
image_names <- list.files(img_dir)
num_images <- length(image_names)
x <- torch_empty(num_images, 3, 224, 224)
for (i in 1:num_images) {
   img_path <- file.path(img_dir, image_names[i])
   img <- img_path |> 
     base_loader() |>  
     transform_to_tensor() |>  
     transform_resize(c(224, 224)) |>  
     # normalize with imagenet mean and stds.
     transform_normalize(
       mean = c(0.485, 0.456, 0.406),
       std = c(0.229, 0.224, 0.225)
     )
   x[i,,, ] <- img
}

model_imagenet <- torchvision::model_resnet18(pretrained = TRUE)
model_imagenet$eval() # put the model in evaluation mode

preds <- model_imagenet(x)
top3 <- torch_topk(preds, dim = 2, k = 3)

mapping <- jsonlite::read_json("https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json") |> 
  sapply(function(x) x[[2]])

top3_prob <- top3[[1]] |> 
  nnf_softmax(dim = 2) |> 
  torch_unbind() |> 
  lapply(as.numeric)

top3_class <- top3[[2]] |> 
  torch_unbind() |> 
  lapply(function(x) mapping[as.integer(x)])

result <- purrr::map2(top3_prob, top3_class, function(pr, cl) {
  names(pr) <- cl
  pr
})
names(result) <- image_names

print(result)

x <- torch_empty(1, 3, 224, 224)
img_path <- file.path("img/squirrel.jpg") ## CHANGE THIS
img <- img_path |>  
  base_loader() |>  
  transform_to_tensor() |>  
  transform_resize(c(224, 224)) |>  
  # normalize with imagenet mean and stds.
     transform_normalize(
       mean = c(0.485, 0.456, 0.406),
       std = c(0.229, 0.224, 0.225)
     )
x[1,,, ] <- img

preds <- model_imagenet(x)
top3 <- torch_topk(preds, dim = 2, k = 3)
mapping[as.integer(top3[[2]])]

```




```{r}
#| eval: true
#| echo: false

unlink("cifar-100-binary", recursive = TRUE)
```
