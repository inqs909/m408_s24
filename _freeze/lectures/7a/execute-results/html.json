{
  "hash": "896ecf9667c6ef8df47d389ed3a87012",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Linear Regression\"\nsubtitle: \"Estimation Procedures\"\nformat:\n  revealjs:\n    scrollable: true\n    navigation-mode: vertical\n    controls-layout: bottom-right\n    controls-tutorial: true\n    incremental: false \n    chalkboard:\n      src: chalkboard.json\n      storage: chalkboard_pres\n      theme: whiteboard\n      chalk-width: 4\nknitr:\n  opts_chunk: \n    echo: false\n    eval: false\n    message: false\n    warnings: false\n    comment: \"#>\" \n\neditor: visual\n---\n\n\n\n\n## Learning Objectives\n\n-   Estimation\n\n-   Ordinary Least Squares\n\n-   Matrix Formulation\n\n-   Standard Errors\n\n-   Conduct in R\n\n## Updated Quarto HW Document\n\n\n::: {.cell}\n\n```{.default .cell-code}\n---\ntitle: \"Title\"\nauthor: \"Name Here\"\ndate: \"`r format(Sys.time(),'%m-%d-%Y')`\"\nformat: \n  html:\n    toc: true\n    toc-depth: 2\n    code-fold: true\n    code-tools: true\n    code-line-numbers: true\n    embed-resources: true\nknitr:\n  opts_chunk:\n    echo: true\n    message: false\n    warning: false\n    error: true\n    tidy: styler\n    R.options:\n      digits: 3\n      max.print: 100\n---\n\n## Problem 1\n\n## Problem 2\n\n## Problem 3\n\n```\n:::\n\n\n## Resources\n\n[Linear Algebra for Data Science](https://shainarace.github.io/LinearAlgebra/intro.html)\n\n# Estimation\n\n## Estimation\n\n-   Ordinary Least Squares\n\n-   Maximum Likelihood Approach\n\n-   Method of Moments\n\n## Standard Errors\n\n-   Find the variance of the estimate\n\n-   Find the information matrix\n\n-   Use for Inference\n\n# Ordinary Least Squares\n\n## Ordinary Least Squares\n\nFor a data pair $(x_i,y_i)_{i=1}^n$, the ordinary least squares estimator will find the estimates of $\\hat\\beta_0$ and $\\hat\\beta_1$ that minimize the following function:\n\n$$\n\\sum^n_{i=1}\\{y_i-(\\beta_0+\\beta_1x_i)\\}^2\n$$\n\n## Estimates\n\n$$\n\\hat\\beta_0 = \\bar y - \\hat\\beta_1\\bar x\n$$ $$\n\\hat\\beta_1 = \\frac{\\sum^n_{i=1}(y_i-\\bar y)(x_i-\\bar x)}{\\sum^n_{i=1}(x_i-\\bar x)^2}\n$$ $$\n\\hat\\sigma^2 = \\frac{1}{n-2}\\sum^n_{i=1}(y_i-\\hat y_i)^2\n$$\n\n# Matrix Formulation\n\n## Matrix Version of Model\n\n$$\ny_i = \\boldsymbol X_i^\\mathrm T \\boldsymbol \\beta + \\epsilon_i\n$$\n\n-   $y_i$: Outcome Variable\n\n-   $\\boldsymbol X_i=(1, x_i)^\\mathrm T$: Predictors\n\n-   $\\boldsymbol \\beta = (\\beta_0, \\beta_1)^\\mathrm T$: Coefficients\n\n-   $\\epsilon_i$: error term\n\n## Data Matrix Formulation\n\nFor $n$ data points\n\n$$\n\\boldsymbol Y = \\boldsymbol X^\\mathrm T\\boldsymbol \\beta + \\boldsymbol \\epsilon\n$$\n\n-   $\\boldsymbol Y = (y_1, \\cdots, y_n)^\\mathrm T$: Outcome Variable\n\n-   $\\boldsymbol X=(\\boldsymbol X_1, \\cdots, \\boldsymbol X_n)^\\mathrm T$: Predictors\n\n-   $\\boldsymbol \\beta = (\\beta_0, \\beta_1)^\\mathrm T$: Coefficients\n\n-   $\\boldsymbol \\epsilon = (\\epsilon_1, \\cdots, \\epsilon_n)^\\mathrm T$: Error terms\n\n## Least Squares Formula\n\n$$\n(Y - \\boldsymbol X ^\\mathrm T\\boldsymbol \\beta)^\\mathrm T(Y - \\boldsymbol X ^\\mathrm T\\boldsymbol \\beta)\n$$\n\n## Estimates\n\n$$\n\\hat{\\boldsymbol \\beta} = (\\boldsymbol X ^\\mathrm T\\boldsymbol X)^{-1}\\boldsymbol X ^\\mathrm T\\boldsymbol Y\n$$\n\n# Standard Errors\n\n## Estimate for $\\sigma^2$\n\n$$\n\\hat \\sigma^2 = \\frac{1}{n-2} \\sum^n_{i=1} (y_i-\\boldsymbol X_i^\\mathrm T\\hat{\\boldsymbol \\beta})^2\n$$\n\n## Standard Errors of $\\beta$'s\n\n$$\nSE(\\hat\\beta_0)=\\sqrt{\\frac{\\sum^n_{i=1}x_i^2\\hat\\sigma^2}{n\\sum^n_{i=1}(x_i-\\bar x)^2}}\n$$\n\n$$\nSE(\\hat\\beta_1)=\\sqrt\\frac{\\hat\\sigma^2}{\\sum^n_{i=1}(x_i-\\bar x)^2}\n$$\n\n## Standard Errors Matrix Form\n\n$$\nVar(\\hat {\\boldsymbol \\beta}) = (\\boldsymbol X ^\\mathrm T\\boldsymbol X)^{-1} \\hat \\sigma^2\n$$\n\n# R approaches\n\n## Built in Functions\n\nYou can use the `lm` to fit a linear model and extract the estimated values and standard errors\n\n## Matrix Formulation\n\nR is capable of conducting matrix operations with the following functions:\n\n-   `%*%`: matrix multiplication\n\n-   `t()`: transpose a matrix\n\n-   `solve()`: computes the inverse matrix\n\n## Minimization Problem\n\nMinimize the least squares using a numerical methods in R. The `optim()` function will minimize a function for set of parameters. We can minimize a function, least squares function, and supply initial values (0) for the parameters of interest.\n\n## Fit a Line using `lm` for the following data\n\n\n::: {.cell}\n\n:::\n\n\n## Fit a linear model using matrix operation\n\n\n::: {.cell}\n\n:::\n\n\n## Minimizing a function using `optim`\n\nFind the value of x and y that will minimize the following function for any value a and b.\n\n$$\nf(x) = 2(x - 5)^2 + 11 \n$$\n\n\n::: {.cell}\n\n:::\n\n\n## Maximizing a function using `optim`\n\nFind the value of x and y that will minimize the following function for any value a and b.\n\n$$\nf(x) = - 3 (x - 8)^2 + 9 \n$$\n\n\n::: {.cell}\n\n:::\n\n\n## Minimizing function using `optim`\n\nFind the value of x and y that will minimize the following function for any value a and b.\n\n$$\nf(x,y) = \\frac{(x-3)^2}{a^2} + \\frac{(y+4)^2}{b^2}\n$$\n\n\n::: {.cell}\n\n:::\n\n\n## Maximizing function using `optim`\n\nFind the value of $\\lambda$ that maximize the following function:\n\n$$\n\\ell(\\lambda) = \\sum^n_{i=1} -\\lambda+X_i\\log(\\lambda) -\\log(X_i!)\n$$\n\nwith the following data:\n\n\n::: {.cell}\n\n:::\n\n\n## Fit a linear model using `optim`\n\nMinimize:\n\n$$\n\\sum^n_{i=1}(y_i-\\hat y_i)^2\n$$\n\n$$\n\\hat y_i = \\hat \\beta_0 +\\hat\\beta_1 x_i\n$$\n",
    "supporting": [
      "7a_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}