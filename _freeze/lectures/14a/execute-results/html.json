{
  "hash": "51b20de0d4d1c1e4b781e6f861e72dc0",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Deep Learning\"\nformat:\n  revealjs:\n    scrollable: true\n    navigation-mode: vertical\n    controls-layout: bottom-right\n    controls-tutorial: true\n    incremental: false \n    chalkboard:\n      src: chalkboard.json\n      storage: chalkboard_pres\n      theme: whiteboard\n      chalk-width: 4\nknitr:\n  opts_chunk: \n    echo: true\n    eval: true\n    message: false\n    warnings: false\n    comment: \"#>\" \n    \nrevealjs-plugins:\n  - pointer\n  - verticator\n  \nfilters: \n  - reveal-header\n  - code-fullscreen\n\neditor: source\n---\n\n\n\n# Neural Networks\n\n## Neural Networks\n\nNeural networks are a type of machine learning algorithm that are designed to mimic the function of the human brain. They consist of interconnected nodes or \"neurons\" that process information and generate outputs based on the inputs they receive.\n\n## Uses\n\nNeural networks are typically used for tasks such as image recognition, natural language processing, and prediction. They are capable of learning from data and improving their performance over time, which makes them well-suited for complex and dynamic problems.\n\n## Single Layer Neural Networks\n\nA single layer neural networks can be formulated as linear function:\n\n$$\nf(X) = \\beta_0 + \\sum^K_{k=1}\\beta_kh_k(X)\n$$\n\nWhere $X$ is a vector of inputs of length $p$ and $K$ is the number of activations, $\\beta_j$ are the regression coefficients and\n\n$$\nh_k(X) = A_k = g(w_{k0} + \\sum^p_{l1}w_{kl}X_{l})\n$$\n\nwith $g(\\cdot)$ being a nonlinear function and $w_{kl}$ are the weights.\n\n## Nonlinear Function $g(\\cdot)$\n\n-   $g(z) = \\frac{e^z}{1+e^z}$\n\n-   $g(z) = (z)_+ = zI(z\\geq0)$\n\n## Single Layer Neural Network\n\n![](https://www.oreilly.com/api/v2/epubs/9781789808452/files/assets/290136cc-48f2-47b1-bb95-ffdb625b987d.png){fig-align=\"center\"}\n\n## Multilayer Neural Network\n\nMultilayer Neural Networks create multiple hidden layers where each layer feeds into each other which will create a final outcome.\n\n## Multilayer Neural Network\n\n![](https://www.oreilly.com/api/v2/epubs/9781838642709/files/assets/61bc8450-f3ac-4d81-b405-3d748e30d04a.png){fig-align=\"center\"}\n\n\n# TensorFlow\n\n## TensorFlow\n\nTensorflow is an open-source machine learning platform developed by Google. Tensorflow is capable of completing the following tasks:\n\n-   Image Classification\n\n-   Text Classification\n\n-   Regression\n\n-   Time-Series\n\n## Keras\n\nKeras is the API that will talk to Tensorflow via different platforms.\n\n## More Information\n\n[TensorFlow for R](https://tensorflow.rstudio.com/)\n\n# Torch\n\n## Torch\n\nTorch is a scientific computing framework designed to support machine learning in CPU/GPU computing. Torch is capable of computing:\n\n-   Matrix Operations\n\n-   Linear Algebra\n\n-   Neural Networks\n\n-   Numerical Optimization\n\n-   and so much more!\n\n## Torch\n\nTorch can be accessed in both:\n\n-   Pytorch\n\n-   R Torch\n\n## R Torch\n\nR Torch is capable of handling:\n\n-   Image Recognition\n\n-   Tabular Data\n\n-   Time Series Forecasting\n\n-   Audio Processing\n\n## More Information\n\n[![](https://torch.mlverse.org/images/cover.jpg){fig-align=\"center\"}](https://skeydan.github.io/Deep-Learning-and-Scientific-Computing-with-R-torch/)\n\n# R Code\n\n## MNIST\n\nThis is a database of handwritten digits.\n\nWe will use to construct neural networks that will classify images.\n\n\n\n## Installation of Torch\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninstall.packages(\"torch\")\ninstall.packages(\"luz\")\ninstall.packages(\"torchvision\")\ninstall.packages(\"torchdatasets\")\ninstall.packages(\"zeallot\")\n```\n:::\n\n\n## Torch Packages in R\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# \nlibrary(torch)\nlibrary(luz) # high-level interface for torch\nlibrary(torchvision) # for datasets and image transformation\nlibrary(torchdatasets) # for datasets we are going to use\nlibrary(zeallot)\ntorch_manual_seed(13)\n```\n:::\n\n\n\n## MNIST\n\n\n::: {.cell}\n\n```{.r .cell-code}\n###\ntrain_ds <- mnist_dataset(root = \".\", train = TRUE, download = TRUE)\ntest_ds <- mnist_dataset(root = \".\", train = FALSE, download = TRUE)\n\ntrain_ds[1]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> $x\n#>       [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13]\n#>  [1,]    0    0    0    0    0    0    0    0    0     0     0     0     0\n#>  [2,]    0    0    0    0    0    0    0    0    0     0     0     0     0\n#>  [3,]    0    0    0    0    0    0    0    0    0     0     0     0     0\n#>  [4,]    0    0    0    0    0    0    0    0    0     0     0     0     0\n#>  [5,]    0    0    0    0    0    0    0    0    0     0     0     0     0\n#>  [6,]    0    0    0    0    0    0    0    0    0     0     0     0     3\n#>  [7,]    0    0    0    0    0    0    0    0   30    36    94   154   170\n#>  [8,]    0    0    0    0    0    0    0   49  238   253   253   253   253\n#>  [9,]    0    0    0    0    0    0    0   18  219   253   253   253   253\n#> [10,]    0    0    0    0    0    0    0    0   80   156   107   253   253\n#> [11,]    0    0    0    0    0    0    0    0    0    14     1   154   253\n#> [12,]    0    0    0    0    0    0    0    0    0     0     0   139   253\n#> [13,]    0    0    0    0    0    0    0    0    0     0     0    11   190\n#> [14,]    0    0    0    0    0    0    0    0    0     0     0     0    35\n#> [15,]    0    0    0    0    0    0    0    0    0     0     0     0     0\n#> [16,]    0    0    0    0    0    0    0    0    0     0     0     0     0\n#> [17,]    0    0    0    0    0    0    0    0    0     0     0     0     0\n#> [18,]    0    0    0    0    0    0    0    0    0     0     0     0     0\n#> [19,]    0    0    0    0    0    0    0    0    0     0     0     0     0\n#> [20,]    0    0    0    0    0    0    0    0    0     0     0     0    39\n#> [21,]    0    0    0    0    0    0    0    0    0     0    24   114   221\n#> [22,]    0    0    0    0    0    0    0    0   23    66   213   253   253\n#> [23,]    0    0    0    0    0    0   18  171  219   253   253   253   253\n#> [24,]    0    0    0    0   55  172  226  253  253   253   253   244   133\n#> [25,]    0    0    0    0  136  253  253  253  212   135   132    16     0\n#> [26,]    0    0    0    0    0    0    0    0    0     0     0     0     0\n#> [27,]    0    0    0    0    0    0    0    0    0     0     0     0     0\n#> [28,]    0    0    0    0    0    0    0    0    0     0     0     0     0\n#>       [,14] [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22] [,23] [,24] [,25]\n#>  [1,]     0     0     0     0     0     0     0     0     0     0     0     0\n#>  [2,]     0     0     0     0     0     0     0     0     0     0     0     0\n#>  [3,]     0     0     0     0     0     0     0     0     0     0     0     0\n#>  [4,]     0     0     0     0     0     0     0     0     0     0     0     0\n#>  [5,]     0     0     0     0     0     0     0     0     0     0     0     0\n#>  [6,]    18    18    18   126   136   175    26   166   255   247   127     0\n#>  [7,]   253   253   253   253   253   225   172   253   242   195    64     0\n#>  [8,]   253   253   253   253   251    93    82    82    56    39     0     0\n#>  [9,]   253   198   182   247   241     0     0     0     0     0     0     0\n#> [10,]   205    11     0    43   154     0     0     0     0     0     0     0\n#> [11,]    90     0     0     0     0     0     0     0     0     0     0     0\n#> [12,]   190     2     0     0     0     0     0     0     0     0     0     0\n#> [13,]   253    70     0     0     0     0     0     0     0     0     0     0\n#> [14,]   241   225   160   108     1     0     0     0     0     0     0     0\n#> [15,]    81   240   253   253   119    25     0     0     0     0     0     0\n#> [16,]     0    45   186   253   253   150    27     0     0     0     0     0\n#> [17,]     0     0    16    93   252   253   187     0     0     0     0     0\n#> [18,]     0     0     0     0   249   253   249    64     0     0     0     0\n#> [19,]     0    46   130   183   253   253   207     2     0     0     0     0\n#> [20,]   148   229   253   253   253   250   182     0     0     0     0     0\n#> [21,]   253   253   253   253   201    78     0     0     0     0     0     0\n#> [22,]   253   253   198    81     2     0     0     0     0     0     0     0\n#> [23,]   195    80     9     0     0     0     0     0     0     0     0     0\n#> [24,]    11     0     0     0     0     0     0     0     0     0     0     0\n#> [25,]     0     0     0     0     0     0     0     0     0     0     0     0\n#> [26,]     0     0     0     0     0     0     0     0     0     0     0     0\n#> [27,]     0     0     0     0     0     0     0     0     0     0     0     0\n#> [28,]     0     0     0     0     0     0     0     0     0     0     0     0\n#>       [,26] [,27] [,28]\n#>  [1,]     0     0     0\n#>  [2,]     0     0     0\n#>  [3,]     0     0     0\n#>  [4,]     0     0     0\n#>  [5,]     0     0     0\n#>  [6,]     0     0     0\n#>  [7,]     0     0     0\n#>  [8,]     0     0     0\n#>  [9,]     0     0     0\n#> [10,]     0     0     0\n#> [11,]     0     0     0\n#> [12,]     0     0     0\n#> [13,]     0     0     0\n#> [14,]     0     0     0\n#> [15,]     0     0     0\n#> [16,]     0     0     0\n#> [17,]     0     0     0\n#> [18,]     0     0     0\n#> [19,]     0     0     0\n#> [20,]     0     0     0\n#> [21,]     0     0     0\n#> [22,]     0     0     0\n#> [23,]     0     0     0\n#> [24,]     0     0     0\n#> [25,]     0     0     0\n#> [26,]     0     0     0\n#> [27,]     0     0     0\n#> [28,]     0     0     0\n#> \n#> $y\n#> [1] 6\n```\n\n\n:::\n\n```{.r .cell-code}\n# test_ds[2]\n```\n:::\n\n\n\n## Transforming Data\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# \n# ###\n# transform <- function(x) {\n#   x |> \n#     torch_tensor()  |> \n#     torch_flatten() |> \n#     torch_div(255)\n# }\n# train_ds <- mnist_dataset(\n#   root = \".\",\n#   train = TRUE,\n#   download = TRUE,\n#   transform = transform\n# )\n# test_ds <- mnist_dataset(\n#   root = \".\",\n#   train = FALSE,\n#   download = TRUE,\n#   transform = transform\n# )\n# ###\n# \n# \n# ###\n# modelnn <- nn_module(\n#   initialize = function() {\n#     self$linear1 <- nn_linear(in_features = 28*28, out_features = 256)\n#     self$linear2 <- nn_linear(in_features = 256, out_features = 128)\n#     self$linear3 <- nn_linear(in_features = 128, out_features = 10)\n# \n#     self$drop1 <- nn_dropout(p = 0.4)\n#     self$drop2 <- nn_dropout(p = 0.3)\n# \n#     self$activation <- nn_relu()\n#   },\n#   forward = function(x) {\n#     x |> \n#       self$linear1() |> \n#       self$activation() |> \n#       self$drop1() |> \n# \n#       self$linear2() |> \n#       self$activation() |> \n#       self$drop2() |> \n#       self$linear3()\n#   }\n# )\n# ###\n# \n# \n# ###\n# print(modelnn())\n# ###\n# \n# \n# ###\n# modelnn <- modelnn |> \n#   setup(\n#     loss = nn_cross_entropy_loss(),\n#     optimizer = optim_rmsprop,\n#     metrics = list(luz_metric_accuracy())\n#   )\n# ###\n# \n# ###\n# system.time(\n#    fitted <- modelnn |> \n#       fit(\n#         data = train_ds,\n#         epochs = 5,\n#         valid_data = 0.2,\n#         dataloader_options = list(batch_size = 256),\n#         verbose = FALSE\n#       )\n#  )\n# plot(fitted)\n# ###\n# \n# ###\n# accuracy <- function(pred, truth) {\n#    mean(pred == truth) }\n# \n# # gets the true classes from all observations in test_ds.\n# truth <- sapply(seq_along(test_ds), function(x) test_ds[x][[2]])\n# \n# fitted |> \n#   predict(test_ds) |> \n#   torch_argmax(dim = 2) |> # the predicted class is the one with higher 'logit'.\n#   as_array() |>  # we convert to an R object\n#   accuracy(truth)\n# ###\n# \n# ###\n# modellr <- nn_module(\n#   initialize = function() {\n#     self$linear <- nn_linear(784, 10)\n#   },\n#   forward = function(x) {\n#     self$linear(x)\n#   }\n# )\n# print(modellr())\n# ###\n# \n# ###\n# fit_modellr <- modellr |> \n#   setup(\n#     loss = nn_cross_entropy_loss(),\n#     optimizer = optim_rmsprop,\n#     metrics = list(luz_metric_accuracy())\n#   ) |> \n#   fit(\n#     data = train_ds,\n#     epochs = 5,\n#     valid_data = 0.2,\n#     dataloader_options = list(batch_size = 128)\n#   )\n# \n# fit_modellr |> \n#   predict(test_ds) |> \n#   torch_argmax(dim = 2) |>   # the predicted class is the one with higher 'logit'.\n#   as_array() |>  # we convert to an R object\n#   accuracy(truth)\n# \n# \n# # alternatively one can use the `evaluate` function to get the results\n# # on the test_ds\n# evaluate(fit_modellr, test_ds)\n# ###\n```\n:::",
    "supporting": [
      "14a_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}