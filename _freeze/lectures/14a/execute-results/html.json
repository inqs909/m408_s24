{
  "hash": "23e71a8408e8f05245c828a951af1b05",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Deep Learning\"\nformat:\n  revealjs:\n    scrollable: true\n    navigation-mode: vertical\n    controls-layout: bottom-right\n    controls-tutorial: true\n    incremental: false \n    chalkboard:\n      src: chalkboard.json\n      storage: chalkboard_pres\n      theme: whiteboard\n      chalk-width: 4\nknitr:\n  opts_chunk: \n    echo: true\n    eval: true\n    message: false\n    warnings: false\n    comment: \"#>\" \n    \nrevealjs-plugins:\n  - pointer\n  - verticator\n  \nfilters: \n  - reveal-header\n  - code-fullscreen\n\neditor: source\n---\n\n\n\n# Neural Networks\n\n## Neural Networks\n\nNeural networks are a type of machine learning algorithm that are designed to mimic the function of the human brain. They consist of interconnected nodes or \"neurons\" that process information and generate outputs based on the inputs they receive.\n\n## Uses\n\nNeural networks are typically used for tasks such as image recognition, natural language processing, and prediction. They are capable of learning from data and improving their performance over time, which makes them well-suited for complex and dynamic problems.\n\n## Single Layer Neural Networks\n\nA single layer neural networks can be formulated as linear function:\n\n$$\nf(X) = \\beta_0 + \\sum^K_{k=1}\\beta_kh_k(X)\n$$\n\nWhere $X$ is a vector of inputs of length $p$ and $K$ is the number of activations, $\\beta_j$ are the regression coefficients and\n\n$$\nh_k(X) = A_k = g(w_{k0} + \\sum^p_{l1}w_{kl}X_{l})\n$$\n\nwith $g(\\cdot)$ being a nonlinear function and $w_{kl}$ are the weights.\n\n## Nonlinear Function $g(\\cdot)$\n\n-   $g(z) = \\frac{e^z}{1+e^z}$\n\n-   $g(z) = (z)_+ = zI(z\\geq0)$\n\n## Single Layer Neural Network\n\n![](https://www.oreilly.com/api/v2/epubs/9781789808452/files/assets/290136cc-48f2-47b1-bb95-ffdb625b987d.png){fig-align=\"center\"}\n\n## Multilayer Neural Network\n\nMultilayer Neural Networks create multiple hidden layers where each layer feeds into each other which will create a final outcome.\n\n## Multilayer Neural Network\n\n![](https://www.oreilly.com/api/v2/epubs/9781838642709/files/assets/61bc8450-f3ac-4d81-b405-3d748e30d04a.png){fig-align=\"center\"}\n\n\n# TensorFlow\n\n## TensorFlow\n\nTensorflow is an open-source machine learning platform developed by Google. Tensorflow is capable of completing the following tasks:\n\n-   Image Classification\n\n-   Text Classification\n\n-   Regression\n\n-   Time-Series\n\n## Keras\n\nKeras is the API that will talk to Tensorflow via different platforms.\n\n## More Information\n\n[TensorFlow for R](https://tensorflow.rstudio.com/)\n\n# Torch\n\n## Torch\n\nTorch is a scientific computing framework designed to support machine learning in CPU/GPU computing. Torch is capable of computing:\n\n-   Matrix Operations\n\n-   Linear Algebra\n\n-   Neural Networks\n\n-   Numerical Optimization\n\n-   and so much more!\n\n## Torch\n\nTorch can be accessed in both:\n\n-   Pytorch\n\n-   R Torch\n\n## R Torch\n\nR Torch is capable of handling:\n\n-   Image Recognition\n\n-   Tabular Data\n\n-   Time Series Forecasting\n\n-   Audio Processing\n\n## More Information\n\n[![](https://torch.mlverse.org/images/cover.jpg){fig-align=\"center\"}](https://skeydan.github.io/Deep-Learning-and-Scientific-Computing-with-R-torch/)\n\n# R Code\n\n## MNIST\n\nThis is a database of handwritten digits.\n\nWe will use to construct neural networks that will classify images.\n\n## MNIST\n\n## Installation of Torch\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninstall.packages(\"torch\")\ninstall.packages(\"luz\")\ninstall.packages(\"torchvision\")\ninstall.packages(\"torchdatasets\")\ninstall.packages(\"zeallot\")\n```\n:::\n\n\n## Torch in R\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# \nlibrary(torch)\nlibrary(luz) # high-level interface for torch\nlibrary(torchvision) # for datasets and image transformation\nlibrary(torchdatasets) # for datasets we are going to use\nlibrary(zeallot)\ntorch_manual_seed(13)\n\n###\ntrain_ds <- mnist_dataset(root = \".\", train = TRUE, download = TRUE)\ntest_ds <- mnist_dataset(root = \".\", train = FALSE, download = TRUE)\n\ntrain_ds[1]\nstr(test_ds[2])\n\nlength(train_ds)\nlength(test_ds)\n###\n\n# \n# ###\n# transform <- function(x) {\n#   x |> \n#     torch_tensor()  |> \n#     torch_flatten() |> \n#     torch_div(255)\n# }\n# train_ds <- mnist_dataset(\n#   root = \".\",\n#   train = TRUE,\n#   download = TRUE,\n#   transform = transform\n# )\n# test_ds <- mnist_dataset(\n#   root = \".\",\n#   train = FALSE,\n#   download = TRUE,\n#   transform = transform\n# )\n# ###\n# \n# \n# ###\n# modelnn <- nn_module(\n#   initialize = function() {\n#     self$linear1 <- nn_linear(in_features = 28*28, out_features = 256)\n#     self$linear2 <- nn_linear(in_features = 256, out_features = 128)\n#     self$linear3 <- nn_linear(in_features = 128, out_features = 10)\n# \n#     self$drop1 <- nn_dropout(p = 0.4)\n#     self$drop2 <- nn_dropout(p = 0.3)\n# \n#     self$activation <- nn_relu()\n#   },\n#   forward = function(x) {\n#     x |> \n#       self$linear1() |> \n#       self$activation() |> \n#       self$drop1() |> \n# \n#       self$linear2() |> \n#       self$activation() |> \n#       self$drop2() |> \n#       self$linear3()\n#   }\n# )\n# ###\n# \n# \n# ###\n# print(modelnn())\n# ###\n# \n# \n# ###\n# modelnn <- modelnn |> \n#   setup(\n#     loss = nn_cross_entropy_loss(),\n#     optimizer = optim_rmsprop,\n#     metrics = list(luz_metric_accuracy())\n#   )\n# ###\n# \n# ###\n# system.time(\n#    fitted <- modelnn |> \n#       fit(\n#         data = train_ds,\n#         epochs = 5,\n#         valid_data = 0.2,\n#         dataloader_options = list(batch_size = 256),\n#         verbose = FALSE\n#       )\n#  )\n# plot(fitted)\n# ###\n# \n# ###\n# accuracy <- function(pred, truth) {\n#    mean(pred == truth) }\n# \n# # gets the true classes from all observations in test_ds.\n# truth <- sapply(seq_along(test_ds), function(x) test_ds[x][[2]])\n# \n# fitted |> \n#   predict(test_ds) |> \n#   torch_argmax(dim = 2) |> # the predicted class is the one with higher 'logit'.\n#   as_array() |>  # we convert to an R object\n#   accuracy(truth)\n# ###\n# \n# ###\n# modellr <- nn_module(\n#   initialize = function() {\n#     self$linear <- nn_linear(784, 10)\n#   },\n#   forward = function(x) {\n#     self$linear(x)\n#   }\n# )\n# print(modellr())\n# ###\n# \n# ###\n# fit_modellr <- modellr |> \n#   setup(\n#     loss = nn_cross_entropy_loss(),\n#     optimizer = optim_rmsprop,\n#     metrics = list(luz_metric_accuracy())\n#   ) |> \n#   fit(\n#     data = train_ds,\n#     epochs = 5,\n#     valid_data = 0.2,\n#     dataloader_options = list(batch_size = 128)\n#   )\n# \n# fit_modellr |> \n#   predict(test_ds) |> \n#   torch_argmax(dim = 2) |>   # the predicted class is the one with higher 'logit'.\n#   as_array() |>  # we convert to an R object\n#   accuracy(truth)\n# \n# \n# # alternatively one can use the `evaluate` function to get the results\n# # on the test_ds\n# evaluate(fit_modellr, test_ds)\n# ###\n```\n:::",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}